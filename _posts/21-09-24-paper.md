---
title: ğŸ’¡ Paper
tags: paper ğŸ’¡ ğŸ”¥
mathjax_autoNumber: false
---

Self-supervised learning with image based synthetic teacher model   
(ì´ë¯¸ì§€ ê¸°ë°˜ì˜ ê°€ìƒ êµì‚¬ ëª¨ë¸ì„ ì´ìš©í•œ ìê¸° ì§€ë„ í•™ìŠµ)

Synthetic ì´ë¯¸ì§€ ê¸°ë°˜ì˜ êµì‚¬ ëª¨ë¸ì„ ì´ìš©í•œ Self-training

<!--more-->

# êµ­ë¬¸ ìš”ì•½ / ì˜ë¬¸ ìš”ì•½

ImageNetì˜ ë°ì´í„° ê³µê°œë¥¼ ì‹œì‘ìœ¼ë¡œ Data-driven ê¸°ë°˜ì˜ Supervised learningì´ ì—¬ëŸ¬ visual task ë¶„ì•¼ì—ì„œ ì¢‹ì€ ì„±ê³¼ë¥¼ ê±°ë‘ê³  ìˆë‹¤. AIëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ê·¸ì— ë§ëŠ” ì–‘ì§ˆì˜ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ë§ì´ í™•ë³´í•˜ëŠëƒê°€ ê²°êµ­ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢Œìš°í•˜ê²Œ ë˜ëŠ”ë°, ë¬¸ì œì™€ ë„ë©”ì¸ì— ë§ëŠ” annotation ë°ì´í„°ë¥¼ ì–»ê¸° ìœ„í•œ ë¹„ìš©ì€ ë§¤ìš° ë¹„ì‹¸ë‹¤.

ì´ ë•Œ í˜„ì‹¤ ì„¸ê³„ì™€ ë¹„ìŠ·í•˜ê²Œ êµ¬í˜„ëœ ì‹œë®¬ë ˆì´ì…˜ì„ ì‚¬ìš©í•˜ë©´ ê°€ìƒì˜ ê³µê°„ì—ì„œ ì›í•˜ëŠ” Ground Truth ë°ì´í„°ë“¤ì„ ë¹„êµì  ì‰½ê²Œ ì–»ì„ ìˆ˜ ìˆë‹¤. ì»´í“¨í„° ê·¸ë˜í”½ê³¼ ê³„ì‚°ì‹ì— ì˜í•˜ì—¬ ì´ë¯¸ì§€, ì„¼ì„œ, Bounding box, class ì •ë³´ ë“±ì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ë¬´í•œíˆ ë§ì€ synthetic ë°ì´í„°ë“¤ì„ ì¶”ì¶œí•˜ê³ , ì´ ë°ì´í„°ë“¤ì„ AI í•™ìŠµì— ì´ìš©í•  ìˆ˜ ìˆë‹¤ë©´ human resourceê°€ ë°œìƒí•˜ëŠ” annotation ì‘ì—… ì–‘ì´ í˜„ì €íˆ ì¤„ì–´ë“¤ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

Synthetic ë°ì´í„°ë¡œ í•™ìŠµí•œ AI ëª¨ë¸ì´ í˜„ì‹¤ ì„¸ê³„ì—ì„œ ì˜ ë™ì‘í•˜ê¸° ìœ„í•´ì„œëŠ” ì‹¤ì œ ë°ì´í„°ì™€ synthetic ë°ì´í„° ê°„ gapì„ ìµœì†Œí™” í•´ì•¼í•˜ëŠ”ë°, ì´ë¥¼ ìœ„í•´ Generative model, Adversarial learning, Pseudo-labeling ë“±ì˜ ê¸°ë²•ë“¤ì„ ì´ìš©í•œ Unsupervised Domain Adaptationì´ ë§ì´ ì—°êµ¬ ë˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ì—°êµ¬ê°€ Domain shiftë¥¼ ì¤„ì´ëŠ” ë°ì—ë§Œ ëª©ì ì„ ë‘ê³  ìˆê³  unlabeled ë°ì´í„° í™œìš© ë°©ì•ˆì—ëŠ” ì§‘ì¤‘í•˜ê³  ìˆì§€ ì•Šë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Synthetic ë°ì´í„°ë¥¼ ì´ìš©í•œ Unsupervised Domain Adaptation (UDA)ì— ì•½ê°„ì˜ labeled ë°ì´í„°ê°€ ìˆì„ ê²½ìš° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Semi-supervised learning (SSL)ì„ ê²°í•©í•˜ì—¬ domain í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì˜ì¡´ì„±ì„ ê°ì†Œì‹œí‚¤ê³ , ê°–ê³  ìˆëŠ” unlabeled ë°ì´í„°ê¹Œì§€ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” UDAS (UDA + SSL) ëª¨ë¸ì„ ì œì•ˆí•œë‹¤. 

- í•µì‹¬ì–´: Unsupervised Domain Adaptation, Semi-supervised learning, Self-training, Pseudo-Labeling, Consistency learning, Synthetic data

# 1. ì„œë¡ 

ImageNetì˜ ë°ì´í„° ê³µê°œë¥¼ ì‹œì‘ìœ¼ë¡œ Data-driven ê¸°ë°˜ì˜ Supervised learningì´ ì—¬ëŸ¬ visual task ë¶„ì•¼ì—ì„œ ì¢‹ì€ ì„±ê³¼ë¥¼ ê±°ë’€ë‹¤. ê²€ì¦ëœ ì¢‹ì€ ëª¨ë¸ë“¤ì´ ì´ë¯¸ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì—, íŠ¹ì • ë¬¸ì œì— ë§ëŠ” AIëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ê·¸ì— ë§ëŠ” ì–‘ì§ˆì˜ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ë§ì´ í™•ë³´í•˜ëŠëƒê°€ ê²°êµ­ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢Œìš°í•˜ê²Œ ë˜ì—ˆë‹¤.

í•˜ì§€ë§Œ íŠ¹ì • ë„ë©”ì¸ì˜ taskì— ë§ëŠ” ë°ì´í„°ë¥¼ í™•ë³´í•˜ê³ , ê·¸ ë°ì´í„°ì— labeling í•˜ëŠ” ê²ƒì€ ë§ì€ ì‹œê°„ê³¼ ë¹„ìš©ì„ í•„ìš”ë¡œ í•œë‹¤. ì´ëŸ¬í•œ ë°ì´í„° ì˜ì¡´ì ì¸ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë”ë¼ë„ íš¨ê³¼ì ì¸ í•™ìŠµì„ í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì—°êµ¬ë“¤ì´ ì§„í–‰ë˜ê³  ìˆë‹¤. ìœ ì‚¬í•œ taskì—ì„œ í•™ìŠµëœ pretrain ëª¨ë¸ì„ ê°€ì ¸ì™€ target taskì— ì ìš©í•˜ëŠ” Transfer Learning, Domain Adaptation, ê·¸ë¦¬ê³  labeled dataê°€ ì ê±°ë‚˜ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” Semi-Supervised Learning, Self-Supervised Learning ë“±ì˜ ì—°êµ¬ë“¤ì´ ìˆë‹¤.

Labeling ì‘ì—…ì˜ ë¹„ìš©ì´ í° ë¬¸ì œë„ ìˆì§€ë§Œ íŠ¹ì • ìƒí™©ì— ëŒ€í•œ ë°ì´í„° ìì²´ë¥¼ ì–»ê¸° ì–´ë ¤ìš´ ê²½ìš°ë„ ìˆë‹¤. íŠ¹íˆë‚˜ ììœ¨ì£¼í–‰ì°¨ëŸ‰, ë¡œë³´í‹±ìŠ¤ ë¶„ì•¼ì—ì„œëŠ” í˜„ì‹¤ ì„¸ê³„ì—ì„œ ì–»ê¸° ì–´ë ¤ìš´ ë°ì´í„°ë“¤ì´ ì¡´ì¬í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ êµì°¨ë¡œ í•œê°€ìš´ë°ì— ì‚¬ëŒì´ ìˆëŠ” ë°ì´í„°ë‚˜, ë¡œë´‡ì˜ ì¹´ë©”ë¼ ì‹œì ì—ì„œì˜ ë°ì´í„° ë“±ì€ ì‰½ê²Œ íšë“í•  ìˆ˜ê°€ ì—†ì„ ê²ƒì´ë‹¤.

ì´ ê²½ìš° ì‹¤ì œ ì„¸ê³„ë¥¼ digital twin í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” ë°©ì•ˆì´ ìˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ì„ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ í˜„ì‹¤ ì„¸ê³„ì—ì„œ ì¬í˜„í•  ìˆ˜ ì—†ëŠ” ìƒí™©ë“¤ì„ ì—°ì¶œí•˜ê³  í™˜ê²½ì„ ììœ ìì¬ë¡œ ë³€ê²½í•˜ì—¬ ë°ì´í„°ë“¤ì„ ì¶”ì¶œí•  ìˆ˜ê°€ ìˆë‹¤. ì»´í“¨í„° ê·¸ë˜í”½ì— ì˜í•´ RGB ì´ë¯¸ì§€, depth ë°ì´í„°, ê°ì²´ì˜ bounding box, pixel ë³„ class, optical flow ë“±ì˜ ì •í™•í•œ Ground Truth ë°ì´í„°ë“¤ì´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ë„ë¡ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì œì‘ ë¹„ìš©ì´ ì €ë ´í•œ synthetic ë°ì´í„°ë¥¼ ì´ìš©í•´ AI í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

Synthetic ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ í•™ìŠµí•œ ëª¨ë¸ì´ í˜„ì‹¤ ì„¸ê³„ì—ì„œ ì˜ ë™ì‘í•˜ê¸° ìœ„í•´ì„œëŠ” ì‹¤ì œ ì„¸ê³„ì™€ ì‹œë®¬ë ˆì´ì…˜ ê°„ì˜ ê²©ì°¨ê°€ ì‘ì•„ì•¼ë§Œ í•œë‹¤. í•˜ì§€ë§Œ ì‹œë®¬ë ˆì´ì…˜ì„ ìµœëŒ€í•œ ì‚¬ì‹¤ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ë§ì€ ë…¸ë ¥ì´ ë“¤ì–´ê°€ê³ , ì‹¤ì œ ì„¸ê³„ì˜ ëª¨ë“  ë°ì´í„°ë“¤ì„ ëª¨ë¸ë§í•˜ê¸°ì—ëŠ” ì‰½ì§€ ì•Šì€ ì¼ì´ë‹¤.

ì´ëŸ¬í•œ synthetic ë°ì´í„°ì˜ ì¥ë‹¨ì ì„ ì´í•´í•˜ê³  synthetic ë°ì´í„°ì™€ í˜„ì‹¤ ë°ì´í„°ì™€ì˜ domain distribution gapì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” Unsupervised Domain Adaptation ë°©ë²•ë¡ ë“¤ì´ ì—°êµ¬ë˜ê³  ìˆë‹¤. Generative ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ adversarial learning, self-training ë“±ì„ ê²°í•©í•œ ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ì œì‹œë˜ê³  ìˆëŠ”ë°, ëŒ€ë¶€ë¶„ì˜ ì—°êµ¬ë“¤ì´ Domain shift ìì²´ë¥¼ ê°ì†Œì‹œí‚¤ëŠ” ì—°êµ¬ì— ì§‘ì¤‘í•˜ê³  ìˆë‹¤. Target ë°ì´í„°ê°€ ì—†ë‹¤ëŠ” ê°€ì •í•˜ì— ë¬¸ì œê°€ ì „ê°œë˜ê¸° ë•Œë¬¸ì— ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì˜¤ê¸° ì–´ë ¤ì›Œì§„ë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” synthetic ë°ì´í„°ë¥¼ í™œìš©í•œ Unsupervised Domain Adaptation (UDA)ì„ ìˆ˜í–‰í•˜ë©´ì„œ ì†ŒëŸ‰ì˜ labeled target ë°ì´í„°ì™€ ë‹¤ëŸ‰ì˜ unlabeled targetë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ Semi-supervised learning (SSL)ì„ ê²°í•©í•œ UDAS (UDA + SSL) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. 

# 2. ê´€ë ¨ ì—°êµ¬

## 2.1. Semantic Segmentation

Semantic segmentation(SS) ëŠ” ì´ë¯¸ì§€ì˜ ê° í”½ì…€ì´ ì–´ëŠ í´ë˜ìŠ¤ì— ì†í•˜ëŠ” ì§€ ì˜ˆì¸¡í•˜ëŠ” ê²ƒìœ¼ë¡œ, ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ ì˜ë¯¸ì™€ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì—¬ ë” ê¹Šì´ ìˆê²Œ ì´í•´í•˜ëŠ” ì‘ì—…ì´ë‹¤. í”½ì…€ ìˆ˜ì¤€ì˜ labelingì´ ìˆ˜í–‰ë˜ê¸° ë•Œë¬¸ì— dense labeling task ë¼ê³  ë¶ˆë¦¬ê³ , ì´ëŠ” classification ì´ë‚˜ localizationì— ë¹„í•´ ì–´ë ¤ìš´ ë¬¸ì œë¡œ ë¶„ë¥˜ëœë‹¤.

SS ëª¨ë¸ì€ Supervised-learning ê¸°ë°˜ì˜ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ê°€ ë‚˜ì˜¤ë©´ì„œ ì„±ëŠ¥ì´ ìƒë‹¹íˆ ê°œì„ ë˜ì—ˆëŠ”ë° ìµœê·¼ì—ëŠ” ì…ë ¥ ê³µê°„ ì°¨ì›ì„ ìœ ì§€í•˜ë©° ì „ì—­ì˜ semantic ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•´ encoder, decoderë¡œ êµ¬ì„±ëœ auto-encoder êµ¬ì¡°ê°€ ë§ì´ ì‚¬ìš©ë˜ê³  ìˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ FCN[1], PSPNet[2], DRN[3], DeepLab[4] ë“±ê³¼ ê°™ì€ ì•„í‚¤í…ì²˜ë“¤ì´ ì œì•ˆë˜ì—ˆìœ¼ë©° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆë‹¤.

í•˜ì§€ë§Œ ëŒ€ëŸ‰ì˜ labeled ë°ì´í„°ì— ì˜ì¡´ì ì´ë¼ ë°ì´í„°ì…‹ì„ í™•ë³´í•˜ëŠ” ë°ì— ë§ì€ ì‹œê°„ì„ ë“¤ì—¬ì•¼ í•œë‹¤. í”½ì…€ ë³„ë¡œ annotation í•˜ëŠ” ê²ƒì€ ë‹¤ë¥¸ visual task ì— ë¹„í•´ ë¹„ìš©ê³¼ ì‹œê°„ì´ ë§ì´ ì†Œìš”ë˜ê¸° ë•Œë¬¸ì— ì›í•˜ëŠ” ë„ë©”ì¸ì˜ ë°ì´í„°ë¥¼ ì–»ê¸°ê°€ ì‰½ì§€ ì•Šë‹¤.

ì¦‰, synthetic ë°ì´í„°ì— ëŒ€í•œ í™œìš©ì²˜ê°€ ë†’ì€ taskë¡œ ë¶„ë¥˜ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë³¸ ë…¼ë¬¸ì—ì„œëŠ” semantic segmentationì„ downstream taskë¡œ ì„¤ì •í•˜ì—¬ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ê³ ì í•œë‹¤. ì–‘ì´ ë§ê³  ì‰½ê²Œ ì–»ì„ ìˆ˜ ìˆëŠ” synthetic ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì§€ì‹ì„ ì¶”ì¶œí•˜ê³  ì´ë¥¼ í™œìš©í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ labeling í•˜ëŠ” ë°ì´í„°ì˜ ì–‘ì„ ì¤„ì´ê³ ì í•œë‹¤.

## 2.3. Unsupervised Domain Adaptation

ì¼ë°˜ì ìœ¼ë¡œ labeled ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ pre-trainedëœ í° ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ transfer learningì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì´ ìˆë‹¤. Transfer learningì„ í•˜ê¸° ìœ„í•´ì„œë„ í•´ë‹¹ ë„ë©”ì¸ì— ë§ëŠ” labeled ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ë§Œ Domain Adaptation(DA)ì€ ë‹¤ë¥¸ ë„ë©”ì¸(Source)ì—ì„œ ë°°ìš´ ì§€ì‹ì„ ì‚¬ìš©í•´ ìƒˆë¡œìš´ ë„ë©”ì¸(Target)ì˜ labeled ë°ì´í„°ê°€ ì—†ëŠ” ìƒí™©ì—ì„œë„ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ë‹¤. Zero-shot learning, few-shot learning, self-supervised learningê³¼ í•¨ê»˜ sample-efficient learningì˜ í•œ ìœ í˜•ì´ë‹¤.

![](/assets/images/21-09-24-paper-domain-adaptation.png)

Source ë„ë©”ì¸ê³¼ target ë„ë©”ì¸ ê°„ì˜ ë°ì´í„° ë¶„í¬ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— source ë„ë©”ì¸ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì„ target ë„ë©”ì¸ì— ì§ì ‘ì ìœ¼ë¡œ transfer í•˜ê²Œ ë˜ë©´ domain shift(ë˜ëŠ” domain gap)ì™€ dataset biasì— ì˜í•´ ì˜¤ì°¨ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì´ ë•Œ Domain Adaptation ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ë©´ source ì™€ target ë„ë©”ì¸ ê°„ ê²©ì°¨ë¥¼ ì¤„ì´ë©° ë°ì´í„° ë¶„í¬ë¥¼ ìœ ì‚¬í•˜ê²Œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. 

![](/assets/images/21-09-24-paper-adaptation-level.png)

DA ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•œ ì£¼ìš” ì „ëµì€ source ë„ë©”ì¸ê³¼ target ë„ë©”ì¸ ì‚¬ì´ì˜ ê²©ì°¨ë¥¼ ì¤„ì„ìœ¼ë¡œì¨ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì„±ëŠ¥ ì €í•˜ë¥¼ ë§‰ëŠ” ë°©ë²•ì´ë‹¤. Input-level, feature-level, output-levelì—ì„œ ê°ê° adaptation ëª¨ë“ˆì„ ì¶”ê°€í•˜ì—¬ ë„ë©”ì¸ ê°„ ë¶ˆì¼ì¹˜ì„±ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.

ê·¸ ì¤‘ Unsupervised Domain Adaptation(UDA)ëŠ” Target ë„ë©”ì¸ì˜ unlabeled ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸ ë„ë©”ì¸ì˜ labeled ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ì¼ì¢…ì˜ Semi-supervised learningì˜ ë³€í˜•ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. Target ë„ë©”ì¸ì˜ labeled ë°ì´í„°ëŠ” í•„ìš”í•˜ì§€ ì•Šì§€ë§Œ ì¶©ë¶„í•œ ì–‘ì˜ Unlabeled target ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤.

Tzeng, Eric, et al.[5] ëŠ” UDAì— GANì„ ë„ì…í•˜ì—¬ adversarial adaptationì„ ì²˜ìŒ ì œì•ˆí•œ ë…¼ë¬¸ìœ¼ë¡œ, feature levelì— domain discriminatorë¥¼ ì¶”ê°€í•˜ê³  adversarial lossë¥¼ ì‚¬ìš©í•˜ì—¬ domain discrepancyë¥¼ ìµœì†Œí™” í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí–ˆë‹¤. 

Hoffman, Judy, et al.[6] ì—ì„œëŠ” feature levelì— adversarial learningì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , input-levelì—ì„œ source ë„ë©”ì¸ ì´ë¯¸ì§€ë¥¼ target ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•˜ë„ë¡ generative ëª¨ë¸ì„ ë„ì…í•œ ë°©ë²•ì„ ì œì•ˆí–ˆë‹¤. Generative ëª¨ë¸ì„ ë„ì…í•¨ìœ¼ë¡œì¨ input ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ í™•ë¥ ë¶„í¬ë¥¼ ì°¾ì•„ë‚´ê³  ìœ ì‚¬í•œ í™•ë¥ ë¶„í¬ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•´ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤. 

Tsai, Yi-Hsuan, et al.[7] ì—ì„œëŠ” ë‘ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ì´ ë‹¤ë¥´ë”ë¼ë„ segmentation ê²°ê³¼ì— í¬í•¨ë˜ì–´ ìˆëŠ” ê³µê°„ ë ˆì´ì•„ì›ƒ, local context ë“±ì˜ êµ¬ì¡°í™”ëœ íŠ¹ì„±ì€ ìœ ì‚¬í•˜ê¸° ë•Œë¬¸ì— output-levelì— adversarial learningì„ ë„ì…í•˜ì—¬ segmentation ì˜ˆì¸¡ ê²°ê³¼ì˜ ë¶„í¬ë¥¼ ìœ ì‚¬í•˜ê²Œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí–ˆë‹¤.

![](/assets/images/21-09-24-paper-da-methods.png)

ì •ë¦¬í•˜ë©´ ê¸°ì¡´ì˜ UDAì—°êµ¬ëŠ” source ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ë¥¼ target ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•˜ê¸° ìœ„í•´ generative ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜, domain confusionì„ ìœ„í•´ discriminatorë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, adversarial learningì„ í†µí•´ ë‘ ë„ë©”ì¸ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë§ì´ ì—°êµ¬ë˜ê³  ìˆë‹¤. ê·¸ ì™¸ì—ë„ discrepancy-based methods, ë¶„ë¥˜ê¸° ë¶ˆì¼ì¹˜ ë¶„ì„, ì—”íŠ¸ë¡œí”¼ ìµœì†Œí™”, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ ë“±ì˜ ë°©ë²•ë¡ ë“¤ì„ ë³€í˜•í•˜ê±°ë‚˜ ì ì ˆì´ ì„ì–´ê°€ë©° ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ì œì•ˆë˜ê³  ìˆë‹¤. 

UDA ì—°êµ¬ëŠ” ë„ë©”ì¸ ë¶„í¬ì˜ ì°¨ë³„ì„±ì— ë”°ë¼ ì ìš©í•  ìˆ˜ ìˆëŠ” ë„ë©”ì¸ì´ í•œì •ì ì¼ ìˆ˜ ìˆë‹¤. Supervised ì •ë³´ê°€ ì „í˜€ ì—†ê¸° ë•Œë¬¸ì— ë„ë©”ì¸ ë¶„í¬ì— ëŒ€í•´ íŒŒì•…í•˜ëŠ” ê²ƒì´ ë³´ë‹¤ ì–´ë ¤ìš´ ì‘ì—…ì´ ë  ìˆ˜ ìˆê³  íŠ¹ì • ë„ë©”ì¸ í˜ì–´ì— í•œí•´ì„œë§Œ ì˜ ë™ì‘í•˜ëŠ” ëª¨ë¸ì´ ë  ìˆ˜ë„ ìˆë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Unsupervised Domain Adaptationì— Semi-supervised learningì„ ê²°í•©í•˜ì—¬ ì ì€ Labeled target ë°ì´í„°ë¥¼ ê°–ê³  ìˆëŠ” ê²½ìš°ì— ì‰½ê²Œ í•™ìŠµë˜ê³  ì‹¤ì œ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆë„ë¡ ì‹¤ìš©ì„±ì´ ê°•í™”ëœ ë°©ë²•ì„ ì œì•ˆí•œë‹¤.

## 2.3. Semi-supervised learning

Semi-supervised learning(SSL)ì€ ì†ŒëŸ‰ì˜ labeled ë°ì´í„°ë¥¼ ì´ìš©í•œ í•™ìŠµ ë°©ë²•ì´ë‹¤. ì†ŒëŸ‰ì˜ labeled ë°ì´í„°ë¡œë§Œ í•™ìŠµí•˜ê²Œ ë˜ë©´ overfittingê³¼ ê°™ì€ ë¬¸ì œê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ í¬ê¸° ë•Œë¬¸ì— ì†ŒëŸ‰ì˜ labeled ë°ì´í„°ì™€ ëŒ€ëŸ‰ì˜ unlabeled ë°ì´í„°ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ semi-supervised learningì´ ì‚¬ìš©ëœë‹¤.

![](/assets/images/21-09-24-paper-self-training.png)

Self-trainingì€ ê°€ì¥ ê°„ë‹¨í•œ SSLë°©ë²•ìœ¼ë¡œ, ì†ŒëŸ‰ì˜ labeled ë°ì´í„°ë¡œ ì¶©ë¶„íˆ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ unlabeled ë°ì´í„°ì— pseudo-labeling ì„ í•˜ê³ , pseudo labeled ë°ì´í„°ì™€ labeled ë°ì´í„°ë¥¼ í•¨ê»˜ í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤. Iterationì„ ë°˜ë³µí•  ìˆ˜ë¡ labeled ë°ì´í„°ê°€ ëŠ˜ì–´ë‚˜ê³  í™•ì¥ëœ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ë„ í•¨ê»˜ í–¥ìƒë  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ì²˜ìŒ pseudo-labelingì„ í•˜ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šìœ¼ë©´ error rateì´ ê³„ì†í•´ì„œ ì¦ê°€í•˜ê¸° ë•Œë¬¸ì— ì˜ëª»ëœ ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ë  ìˆ˜ ìˆë‹¤ëŠ” ë¬¸ì œê°€ ìˆë‹¤.

![](/assets/images/21-09-24-paper-entropy-minimization.png)

ê·¸ë˜ì„œ Unlabeled dataë¥¼ í•™ìŠµì‹œí‚¬ ë•Œ pseudo-labelingì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê³ , pseudo-labelì˜ maximum softmax probabilityë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ í™•ë¥ ì˜ confidenceë¥¼ ë†’ì´ê¸° ìœ„í•´ entropy minimizationì„ ì‚¬ìš©í•œë‹¤. ì£¼ë¡œ softmax temperatureë¥¼ ì ìš©í•˜ì—¬ unlabeled ë°ì´í„°ì˜ ì˜ˆì¸¡ê°’ì„ ê³„ì‚°í•  ë•Œ decision boundaryì—ì„œ ë©€ì–´ì§€ë„ë¡ ë” sharpí•˜ê²Œ ì˜ˆì¸¡ í™•ë¥ ê°’ì„ ì •í•œë‹¤. ë‹¨ì¼ ê¸°ë²•ìœ¼ë¡œëŠ” ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì§€ë§Œ ìµœì‹  ì—°êµ¬ì— ë§ì´ ì ìš©í•´ ì‚¬ìš©í•˜ê³  ìˆë‹¤. 

Xie, Qizhe, et al. [8]ëŠ” Teacher-student ê¸°ë°˜ì˜ Self-trainingìœ¼ë¡œ, labeled ë°ì´í„°ë¡œ í•™ìŠµëœ teacherë¥¼ ì´ìš©í•´ unlabeled ë°ì´í„°ì— pseudo-labeling í•˜ê³  ì´ ë°ì´í„°ì— ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ì—¬ student ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì´ë‹¤. Student ëª¨ë¸ì´ ì–´ëŠì •ë„ í•™ìŠµì´ ë˜ë©´ teacher ëª¨ë¸ë¡œ ì„¤ì •í•˜ê³  ë‹¤ì‹œ pseudo labelingì„ ìˆ˜í–‰í•˜ê²Œ ë§Œë“¤ì–´ ë°˜ë³µì ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í–ˆê³  ì´ë¥¼ í†µí•´ SOTAë¥¼ ê¸°ë¡í•  ì •ë„ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ ì—°êµ¬ì´ë‹¤.

Pham, Hieu, et al. [9]ì€ Teacher ëª¨ë¸ê³¼ Student ëª¨ë¸ì„ ë™ì‹œì— í•™ìŠµí•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, Teacher ëª¨ë¸ì´ ì˜ í•™ìŠµë˜ì–´ ìˆì§€ ì•Šë”ë¼ë„ student ëª¨ë¸ê³¼ ìœ ê¸°ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ Co-training ë°©ì‹ì„ ì œì•ˆí•˜ì˜€ë‹¤.

ìµœê·¼ ë§ì´ ì‚¬ìš©ë˜ëŠ” SSL ì ‘ê·¼ë²•ì€ Consistency regularizationì„ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ, unlabeled ë°ì´í„°ì— ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ë”ë¼ë„ ì˜ˆì¸¡ ë¶„í¬ëŠ” ìœ ì§€ëœë‹¤ëŠ” ì•„ì´ë””ì–´ì— ê¸°ì•ˆí•œ ë°©ë²•ì´ë‹¤. ë…¸ì´ì¦ˆê°€ ì—†ëŠ” ì›ë³¸ ë°ì´í„°ì™€ ë…¸ì´ì¦ˆê°€ ì£¼ì…ëœ ë°ì´í„°ë¥¼ ë™ì¼í•œ ì˜ˆì¸¡ ë¶„í¬ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì´ consistency regularizationì˜ ëª©í‘œì´ë‹¤.

Miyato, Takeru, et al. [10]ì€ ì…ë ¥ ë°ì´í„°ì˜ adversarial transformationì„ ìƒì„±í•˜ê³  ì˜ˆì¸¡ ê²°ê³¼ ê°„ì˜ KL-divergenceë¥¼ ì¸¡ì •í•˜ì—¬ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì„ ì œì•ˆí–ˆë‹¤. 

Xie, Qizhe, et al. [11]ì€ ë…¸ì´ì¦ˆ ëŒ€ì‹  ìµœì‹  augmentation ê¸°ë²•ì¸ AutoAugmentë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ê²°ê³¼ ê°„ KL-divergenceë¥¼ lossë¡œ ì‚¬ìš©í•œ ë°©ë²•ìœ¼ë¡œ, ì ì€ labeled ë°ì´í„°ë§Œìœ¼ë¡œ supervised learningì„ ë›°ì–´ë„˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.

ê·¸ë¦¬ê³  Berthelot, David, et al. [12], Sohn, Kihyuk, et al. [13] ë“± Pseudo-labelingê³¼ í•¨ê»˜ augmentation, entropy minimization, consistency regularizationì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ê¸°ë²•ì„ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” holistic methods ì—°êµ¬ë“¤ë„ ë‚˜ì˜¤ê³  ìˆê³  SSL ë¶„ì•¼ì—ì„œ SOTAë¥¼ ê¸°ë¡í•˜ê³  ìˆë‹¤.
 
ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Unlabeled target ë°ì´í„°ì— Kê°œì˜ augmentation ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , ê°€ì¥ í° confidenceë¥¼ ê°–ëŠ” prediction ê°’ë§Œ ì·¨í•˜ëŠ” maximum confidence mapì„ í†µí•´ ì‹ ë¢°ë„ ë†’ì€ pseudo-labelingì„ ìˆ˜í–‰í•œë‹¤.

# 3. ì œì•ˆ ë°©ë²•

## 3.1. ê°œìš”

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Synthetic ë°ì´í„°ë¥¼ ì´ìš©í•œ Unsupervised Domain Adaptation (UDA)ê³¼ ì†ŒëŸ‰ì˜ labeled target ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” Semi-supervised learning (SSL)ì„ ê²°í•©í•˜ì—¬, ë„ë©”ì¸ í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì˜ì¡´ë„ë¥¼ ë‚®ì¶”ê³  semantic segmentationì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” UDAS (UDA + SSL) ëª¨ë¸ì„ ì œì•ˆí•œë‹¤.

![](/assets/images/21-09-24-paper-paper-overview.png)

UDASì˜ ì „ì²´ì ì¸ í”„ë ˆì„ì›Œí¬ëŠ” ê·¸ë¦¼5ê³¼ ê°™ë‹¤. í¬ê²Œ Domain Adaptation ì„ ìœ„í•œ Teacherëª¨ë¸ê³¼ Teacher ëª¨ë¸ë¡œë¶€í„° Knowledge Distillation ì„ ë°›ì•„ ì‹¤ì œ taskë¥¼ ìˆ˜í–‰í•˜ëŠ” Student ëª¨ë¸ ë‘ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.

ê¸°ë³¸ì ì¸ êµ¬ì¡°ëŠ” UDAë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆì–´ì„œ target labeled ë°ì´í„°ê°€ ì—†ë”ë¼ë„ target taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê³ , target labeled ë°ì´í„°ê°€ ëŠ˜ì–´ë‚¨ì— ë”°ë¼ Semi-Domain Adaptation êµ¬ì¡°ë¡œ ë™ì‘í•˜ë©´ì„œ target taskì˜ ì„±ëŠ¥ì´ í–¥ìƒëœë‹¤. ì´ ë•Œ target labeled ë°ì´í„°ë¥¼ ê°„ì ‘ì ìœ¼ë¡œ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ target ë°ì´í„°ì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ë†’ì•„ì§€ì§€ ì•Šë„ë¡ í•œë‹¤. 

DAë¥¼ í†µí•´ í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ unlabeled target ë°ì´í„°ì— pseudo-labelingì„ í•´ì£¼ê³  ì‹¤ì œ target taskë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì€ pseudo-labeling ëœ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ Supervised learning êµ¬ì¡°ë¡œ í•™ìŠµí•¨ìœ¼ë¡œì¨ target ë„ë©”ì¸ì— ë§ì¶° fine-tuning í•œë‹¤.

ë³¸ ë…¼ë¬¸ì˜ contributionì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
    â€¢ Unsupervised Domain Adaptationì™€ Semi-supervised learning ì„ ê²°í•©í•œ ëª¨ë¸ êµ¬ì¡° ì œì•ˆ
    â€¢ Labeled target ë°ì´í„° ì–‘ì„ ì¤„ì˜€ì„ ë•Œ SLë³´ë‹¤ ì•ˆì •ì ì¸ ì„±ëŠ¥
    â€¢ ê¸°ì¡´ UDA SOTA ëŒ€ë¹„ ë†’ì€ mIoU ë‹¬ì„±

## 3.2. Style Transfer

ì‹œê°ì ìœ¼ë¡œ ë´¤ì„ ë•Œ í° ì°¨ì´ê°€ ìˆëŠ” ë°ì´í„°ëŠ” ê·¸ë§Œí¼ í° ë„ë©”ì¸ gap ì´ ìˆì„ ê²ƒì´ë¼ê³  ê°€ì •í•  ìˆ˜ ìˆë‹¤. Input-levelì—ì„œì˜ ë„ë©”ì¸ gapì„ ì¤„ì´ê¸° ìœ„í•´ source ë„ë©”ì¸ì˜ image appearanceê°€ target domainê³¼ ìœ ì‚¬í•˜ë„ë¡ ìƒì„±í•´ë‚¸ë‹¤. ëŒ€í‘œì ì¸ image-to-image translation ë°©ë²•ì¸ CycleGANì„ ì´ìš©í•˜ì—¬ target domain ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¡œ ë³€í˜•ì‹œì¼œ domain adaptation ëª¨ë¸ì˜ source ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ê³ ì í•œë‹¤.

$$ L(G, F, D_x, D_Y) = L_{GAN}(G, D_Y, X, Y) + L_{GAN}(F, D_x, Y, X) + \lambda L_{cyc}(G, F) $$

$$ G^*, F^* = arg min_{G, F} max_{D_x, D_y} L(G, F, D_x, D_y) $$

Xê°€ source domain ìƒ˜í”Œ, Yê°€ target domain ìƒ˜í”Œì´ë¼ê³  í–ˆì„ ë•Œ Xïƒ Yë¡œ ê°€ëŠ” GANì˜ adversarial lossì™€ Yïƒ Xë¡œ ê°€ëŠ” GANì˜ adversarial lossì— ê°ê° ì›ë³¸ìœ¼ë¡œ ë³µêµ¬í•˜ëŠ” cycle consistency lossë¥¼ ë”í•´ì¤€ ê°’ì´ ì´ Lossê°€ ë˜ê³ , ì´ Lossë¥¼ ìµœì†Œí™” í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ G: Xïƒ Y ì™€ F: Yïƒ X ë¥¼ í•™ìŠµì‹œí‚¨ë‹¤.

í•™ìŠµ ì‹œì—ëŠ” Gì™€ Fê°€ í•¨ê»˜ í•™ìŠµë˜ëŠ” êµ¬ì¡°ì´ì§€ë§Œ, ì „ì²´ ì‹¤í—˜ì—ì„œëŠ” F: Yïƒ X ëª¨ë¸ì€ ì‚¬ìš©í•˜ì§€ ì•Šê³  G: Xïƒ Y ë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— GAN ë¶€ë¶„ë§Œ ë„ì‹í™”í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.

![](/assets/images/21-09-24-paper-gan.png)

Source domainê³¼ target domainì˜ ë¶„í¬ë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì´ê¸° ë•Œë¬¸ì— domainê°„ gapì´ ì¤„ì—ˆì„ ê²ƒì´ë¼ê³  ê¸°ëŒ€í•  ìˆ˜ ìˆê³ , G: Xïƒ Y ëª¨ë¸ì„ í†µí•´ ìƒì„±ëœ ë°ì´í„°ëŠ” target domainë¶„í¬ì— ê°€ê¹Œìš´ í˜•íƒœê°€ ë  ìˆ˜ ìˆë‹¤. Source ë„ë©”ì¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒ ë³´ë‹¤ Target domainì˜ ìŠ¤íƒ€ì¼ì— ë§ê²Œ ì´ë¯¸ì§€ë¥¼ ì¬ìƒì„±í•´ì„œ target task ëª¨ë¸ì— ì ìš©í•˜ë©´ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆì—ˆëŠ”ë°, ì´ì— ê´€í•œ ì‹¤í—˜ ê²°ê³¼ëŠ” 4.3.ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

## 3.3. Unsupervised Domain Adaptation

UDA ëª¨ë“ˆì€ Adversarial Generative Model êµ¬ì¡°ë¡œ êµ¬ì„±ëœë‹¤. 3.2.ì—ì„œ Style Transfer ëœ ì´ë¯¸ì§€ê°€ Source ì´ë¯¸ì§€ë¡œ ëŒ€ì²´ë˜ì–´ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤.

Source ì´ë¯¸ì§€ì™€ source labelsì„ ì´ìš©í•˜ì—¬ source ë„ë©”ì¸ ê¸°ë°˜ìœ¼ë¡œ Segmentation ì„ í•™ìŠµí•œë‹¤. Segmentation lossëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë˜ëŠ” pixel-wise cross-entropy lossë¥¼ ì‚¬ìš©í•œë‹¤.

![](/assets/images/21-09-24-paper-uda-module.png)

$$L_{seg} = -\sum_{h=1}^{H}\sum_{w=1}^{W}\sum_{c=1}^{C} y_s^i log(P(x_s^i)) $$

ì¶”ê°€ì ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ ì‹œì—ëŠ” softmax temperatureì™€ confidence-based maskingì„ ì¶”ê°€í•˜ì—¬ ë³´ë‹¤ ì •í™•í•œ ì˜ˆì¸¡ì„ í•˜ë„ë¡ ìœ ë„í•œë‹¤.

í•™ìŠµí•˜ëŠ” Segmentation ëª¨ë¸ì€ source ë„ë©”ì¸ìœ¼ë¡œë¶€í„° í•™ìŠµë˜ê¸° ë•Œë¬¸ì— target ë„ë©”ì¸ì—ì„œëŠ” ì˜ ë™ì‘í•˜ì§€ ì•ŠëŠ”ë‹¤. Target ë„ë©”ì¸ì˜ distributionì´ source ë„ë©”ì¸ê³¼ ìœ ì‚¬í•´ì§€ë„ë¡ í•˜ê¸° ìœ„í•´ prediction ê²°ê³¼ì— adversarial lossë¥¼ ì¶”ê°€í•œë‹¤. ì´ë¥¼ í†µí•´ source ë„ë©”ì¸ì—ì„œ í•™ìŠµí•œ ì§€ì‹ë“¤ì´ target ë„ë©”ì¸ ì˜ì—­ìœ¼ë¡œ ì „ë‹¬ë˜ê³  output-levelì—ì„œë„ domain adaptationì´ ìˆ˜í–‰ëœë‹¤.

$$ L_{adv} = \mathbb{E}[ log(D_p(P(x_s^i))) + log (1 - D_p(P(x_t^j))) ]
 $$

DiscriminatorëŠ” predictionì˜ ê²°ê³¼ë¥¼ ë³´ê³  source domainì˜ predictionì¸ì§€ target domainì˜ predictionì¸ì§€ êµ¬ë¶„í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•  ê²ƒì´ë‹¤.


$$ L_{total} = L_{seg} + \lambda_{adv} L_{adv}$$

UDAë¡œ ë™ì‘í•˜ëŠ” ê²½ìš° ì „ì²´ lossëŠ” segmentation lossì™€ adversarial lossë¥¼ ë”í•œ ê°’ì´ë‹¤. Adversarial lossì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ê¸° adversarial loss termì—ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° $\lambda_{adv}$ ë¥¼ ê³±í•´ì¤€ë‹¤.

## 3.4. Combined Augmentation

Labeled target ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” 3.3.ì˜ ì„œìˆ  ë‚´ìš©ì²˜ëŸ¼ UDA êµ¬ì¡°ë¡œ ë™ì‘í•  ìˆ˜ ìˆì§€ë§Œ ì†ŒëŸ‰ì˜ labeled ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° target ë„ë©”ì¸ì— ëŒ€í•œ ì •ë³´ë¥¼ í† ëŒ€ë¡œ ëª¨ë¸ì´ ë” í–¥ìƒë  ìˆ˜ ìˆë‹¤.

Labeled target ë°ì´í„°ë¥¼ Supervised learning í˜•íƒœë¡œ ê·¸ëŒ€ë¡œ ì´ìš©í•˜ê²Œ ë˜ë©´ source ë„ë©”ì¸ ë°ì´í„°ë¥¼ adaptation í•˜ëŠ” ì •ë³´ì™€ ìƒì¶©ë  ìˆ˜ ìˆê³ , ì¶”í›„ source ë„ë©”ì¸ ë°ì´í„°ê°€ ì¶”ê°€ë¡œ í™•ë³´ë˜ì–´ UDAë¥¼ ì§„í–‰í•œë‹¤ê³  í•  ë•Œ target ë„ë©”ì¸ ë°ì´í„°ì˜ ì§€ì‹ì´ ë„ˆë¬´ ê°•í•´ì„œ ì¶”ê°€ì ì¸ í•™ìŠµì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆë‹¤.

ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë³¸ ì—°êµ¬ì—ì„œëŠ” ë„ë©”ì¸ê³¼ ë…ë¦½ì ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ source ë„ë©”ì¸ ìƒ˜í”Œê³¼ target ë„ë©”ì¸ ìƒ˜í”Œì„ ê²°í•©í•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•œë‹¤. 

Semantic segmentationì€ ê° í”½ì…€ì˜ ì˜ˆì¸¡ê°’ê³¼ ë”ë¶ˆì–´ ì£¼ë³€ pixelì— ëŒ€í•œ ì§€ì—­ì ì¸ ì˜ˆì¸¡ ì •ë³´ë„ í•„ìš”í•œë°, í•œ ì´ë¯¸ì§€ì— source ë„ë©”ì¸ ì´ë¯¸ì§€ì™€ target ë„ë©”ì¸ ì´ë¯¸ì§€ê°€ ê²°í•©ë˜ì–´ ìˆìœ¼ë©´ ë„ë©”ì¸ê³¼ ê´€ê³„ ì—†ì´ ì´ë¯¸ì§€ ìì²´ì˜ representationì„ í•™ìŠµí•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´ ê¸°ì¡´ì˜ CutMix[14]ì˜ í˜•íƒœë¡œ ë‘ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ë¥¼ ì„ì˜ë¡œ ê²°í•©ì‹œì¼œ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•œë‹¤.

CutMixëŠ” ë‘ ì´ë¯¸ì§€ë¥¼ ì„ì–´ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì— í‘œí˜„í•˜ëŠ” Data augmentation ë°©ë²•ì´ë‹¤.  Regularizationê³¼ Localization ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•œ ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ, ëª¨ë¸ì´ ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ì˜ì—­ì„ ë³´ê³  í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•  ìˆ˜ ìˆë‹¤.

$$ r_x \sim Unif \{ 0, W \}, r_w = W \sqrt {1- \lambda}
\\
r_y \sim Unif \{ 0, H \}, r_h = H \sqrt {1- \lambda}
\\
B = \{ r_x , r_y, r_w, r_h \} $$

Cutmix ë°ì´í„° ìƒì„±ì„ ìœ„í•´ ë§¤ ë°°ì¹˜ë§ˆë‹¤ ëœë¤ìœ¼ë¡œ bounding box B ì‚¬ì´ì¦ˆë¥¼ ê²°ì •í•˜ê³ , B ì‚¬ì´ì¦ˆì— ë§ê²Œ binary ë§ˆìŠ¤í¬ Mì„ ìƒì„±í•œë‹¤.  

Source ë„ë©”ì¸ì˜ ìƒ˜í”Œ $x_s$ ì—ì„œ M ì˜ì—­ë§Œí¼ ì§€ìš°ê³ , ê·¸ ë¶€ë¶„ì— target ë„ë©”ì¸ ìƒ˜í”Œ $x_t$ë¥¼ ì±„ìš´ë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ source ë„ë©”ì¸ ìƒ˜í”Œì— ëŒ€í•œ label ë°ì´í„°ì¸ $y_s$ ì—ì„œë„ (0, 1) ì‚¬ì´ì˜ uniform distributionì¸ lambdaë¥¼ í†µí•´ ì™€ í˜ì–´ ë˜ëŠ” labeled cutmix ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤.

![](/assets/images/21-09-24-paper-cutmix-data.png)

ì´ë ‡ê²Œ ìƒì„±ëœ cutmix ë°ì´í„°ì— augmentationì„ ì·¨í•´ ì„ì˜ì˜ ë°ê¸°, ëŒ€ì¡°, color jitter ë“¤ì„ ì¶”ê°€í•œ ë’¤ ê¸°ì¡´ì— í•™ìŠµì— ì‚¬ìš©í•˜ë˜ source ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì…ë ¥ ë°ì´í„°ë¡œ segmentation ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤. Domain Randomizationë…¼ë¬¸ë“¤[15][16][17]ì— ì˜ê±°í•˜ë©´ ëœë¤í•˜ê²Œ ìƒì„±ëœ synthetic ë°ì´í„°ê°€ ì‹¤ì œ ì„¸ê³„ì— ì ìš©í•  ë•Œ ë„ì›€ì´ ëœë‹¤ëŠ” ê²ƒì„ ì‹¤í—˜ì ìœ¼ë¡œ ì•Œ ìˆ˜ ìˆë‹¤.

![](/assets/images/21-09-24-paper-cutmix-flow.png)

Semi-Domain adaptation êµ¬ì¡°ë¡œ ë™ì‘í•  ë•Œ segmentation lossëŠ” Source ë„ë©”ì¸ ì´ë¯¸ì§€ì— ëŒ€í•œ Cross-entropy lossì™€ CutMix ì´ë¯¸ì§€ì— ëŒ€í•œ Cross-entropy lossë¥¼ ë”í•œ ê°’ì´ë‹¤. CutmMix ë°ì´í„°ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ ìœ„í•˜ì—¬ CutMix Loss termì—ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°  ë¥¼ ê³±í•´ì¤€ë‹¤. ì „ì²´ LossëŠ” UDAì—ì„œ cutmixì˜ CE lossê°€ ì¶”ê°€ëœ ê°’ì´ë‹¤.

$ L_{total} = L_seg + \lambda_{cm} L_{cm} + \lambda_{adv} L_{adv} $

## 3.5. Knowledge Distillation

Domain Adaptation ëª¨ë“ˆì„ í†µí•´ ì–»ì–´ì§„ Task model ì´ ìˆì§€ë§Œ Target ë„ë©”ì¸ì—ì„œì˜ Fine-tuningì„ ìœ„í•´ Unlabeled Target ë°ì´í„°ì— Pseudo-labelingì„ í•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•œë‹¤. ì•ì„œ í•™ìŠµí•œ segmentationëª¨ë¸ì€ ì´ì œ Teacher ëª¨ë¸ì´ ë˜ì–´ target ë„ë©”ì¸ì— ì ìš©í•  ëª¨ë¸ì¸ Student ëª¨ë¸ì—ê²Œ Knowledge Distillation í•˜ê²Œ ëœë‹¤.

Teacher ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ Pseudo-labelsë¡œ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ teacher ëª¨ë¸ì´ ê°–ê³  ìˆëŠ” ì˜¤ì°¨ ì •ë³´ê°€ ê·¸ëŒ€ë¡œ ì „íŒŒë˜ê¸° ë•Œë¬¸ì— Sharpening predictions í•´ì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. 

![](/assets/images/21-09-24-paper-pseudo-labeling.png)

Pseudo-labeling ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. Unlabeled target ë°ì´í„°ì— Kê°œì˜ augmentation ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ê°ê° teacher ëª¨ë¸ì„ í†µí•´ prediction probabilityë¥¼ ì–»ëŠ”ë‹¤. Confidence mapì„ ë¹„êµí–ˆì„ ë•Œ ê°€ì¥ ë†’ì€ confidenceì˜ ì˜ˆì¸¡ê°’ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ maximum confidence mapì„ êµ¬ì„±í•˜ê³  ì´ë¥¼ í†µí•´ ë§Œë“¤ì–´ì§„ pseudo-label ì¤‘ì—ì„œ íŠ¹ì • confidence ê°’ ì´ìƒì˜ ì˜ˆì¸¡ ë°ì´í„°ë§Œ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•œë‹¤.

![](/assets/images/21-09-24-paper-student-model.png)

Unlabeled ë°ì´í„°ì— pseudo-labelingì´ ëœ ì´í›„ì—ëŠ” source ë„ë©”ì¸ ë°ì´í„°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. Pseudo-labelingëœ ë°ì´í„°ë“¤ì„ ì´ìš©í•´ Student ëª¨ë¸ì„ Supervised learning ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ê³ , Student ëª¨ë¸ì´ target ë„ë©”ì¸ì— ëŒ€í•˜ì—¬ fine-tuning ë˜ì–´ ë” ë‚˜ì€ ì„±ëŠ¥ì— ë„ë‹¬í•˜ê²Œ ë˜ë©´ ê¸°ì¡´ì˜ pseudo-labeling ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸ í•´ì¤€ë‹¤. ê·¸ë¦¬ê³  ì¬ìƒì„±ëœ pseudo-labeled ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ Student ëª¨ë¸ì´ ê²¬ê³ í•˜ê³  ì‹ ë¢°ë„ ë†’ì€ ë°©í–¥ìœ¼ë¡œ ì¬í•™ìŠµë˜ë„ë¡ êµ¬ì„±í•˜ì—¬ ë°˜ë³µì ì¸ í•™ìŠµì´ ì´ë£¨ì–´ì§€ë„ë¡ í•œë‹¤.

# 4. ì‹¤í—˜ ë° ê²°ê³¼

## 4.1. ì‹¤í—˜ ì„¤ê³„

UDASí”„ë ˆì„ì›Œí¬ë¥¼ ì½”ë“œëŠ” Python 3.8ê³¼ Pytorch 1.9.0 ë²„ì „ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆê³ , ëª¨ë“  ì‹¤í—˜ì€ ë©”ëª¨ë¦¬ 11GBì˜ 1080ti 2ê°œê°€ ì¥ì°©ëœ Ubuntu 20.04 í™˜ê²½ì—ì„œ ì§„í–‰ë˜ì—ˆë‹¤

### 4.1.1. ë°ì´í„°ì…‹

![](/assets/images/21-09-24-paper-dataset.png)dataset

Cityscapes[18]ëŠ” ìœ ëŸ½ 50ê°œ ë„ì‹œì˜ ê±°ë¦¬ì—ì„œ ì°¨ëŸ‰ ì‹œì ìœ¼ë¡œ ìº¡ì³í•œ 2048x1024 í”½ì…€ì˜ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì´ë‹¤. 2,975ê°œì˜ training set, 500ê°œì˜ validation set, 1,595ê°œì˜ test setìœ¼ë¡œ ì´ 5,000ê°œì˜ ì´ë¯¸ì§€ ë°ì´í„°ì™€ pixel-wise semantic labelë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì¶”ê°€ë¡œ label ë˜ì–´ ìˆì§€ ì•Šì€ 19,998 ê°œì˜ raw ì´ë¯¸ì§€ ë°ì´í„°ë„ ì œê³µëœë‹¤.

GTA5[19]ëŠ” ë„ì‹œ ìš´ì „ì„ ìœ„í•œ ëŒ€ê·œëª¨ synthetic ë°ì´í„°ì…‹ ì¤‘ í•˜ë‚˜ì´ë‹¤. ì‚¬ì‹¤ì ì¸ ê·¸ë˜í”½ì„ ë³´ì—¬ì£¼ëŠ” GTA V ê²Œì„ì„ í†µí•´ ë Œë”ë§ ë˜ì—ˆê³  ë¯¸êµ­ ìŠ¤íƒ€ì¼ ë„ì‹œì—ì„œì˜ ìë™ì°¨ ê´€ì ì—ì„œ ì´¬ì˜ë˜ì—ˆë‹¤. 24,966ê°œì˜ 1914x1052 í”½ì…€ì˜ ì´ë¯¸ì§€ì™€ pixel-wise semantic labelë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. Labelì€ Cityspcaesì˜ í´ë˜ìŠ¤ì— ë§ê²Œ 19ê°œ í´ë˜ìŠ¤ë¡œ ì¬ë§¤í•‘ í•  ìˆ˜ ìˆë‹¤.

Cityscapesì™€ GTA5ëŠ” ì‹œê°ì ì¸ appearance ì°¨ì´ê°€ ì¡´ì¬í•˜ì§€ë§Œ ë¹„ìŠ·í•œ ì°¨ëŸ‰ì˜ ë†’ì´ì—ì„œ ë„ë¡œ ìƒí™©ì„ ìº¡ì³í•œ ë°ì´í„°ë¼ëŠ” ì ì—ì„œ êµ¬ì¡°ê°€ ìœ ì‚¬í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. GTA5 ë°ì´í„°ê°€ Cityscapes ë°ì´í„° ì–‘ì— ë¹„í•´ ì•½ 5ë°° ê°€ëŸ‰ ë§ê¸° ë•Œë¬¸ì— GTA5ì˜ ë°ì´í„°ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ ì˜ë¯¸ì™€ êµ¬ì¡°ë¥¼ í•™ìŠµí•˜ê³ , Cityscapes í™˜ê²½ì—ì„œ ì˜ ë™ì‘í•˜ë„ë¡ Cityscapesì˜ unlabeled ë°ì´í„°ê¹Œì§€ ì ì ˆíˆ ì´ìš©í•œë‹¤.

|  Dataset   |   Type    | # of Labeled Data | # of Raw Data | # of Classes |
| :--------: | :-------: | :---------------: | :-----------: | :----------: |
| Cityscapes |   Real    |       5,000       |    19,998     |      19      |
|    GTA     | Synthetic |      24,966       |       -       |      19      |

### 4.1.2. í‰ê°€ Metric

í‰ê°€ metricìœ¼ë¡œëŠ” Semantic segmentation í‰ê°€ ì‹œì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” í´ë˜ìŠ¤ ë³„ IoU(Intersection over Union) ì™€ mIoU(Mean Intersection over Union)ë¥¼ ì‚¬ìš©í•œë‹¤. $TP_i$, $FP_I$, $FN_i$ ëŠ” íŠ¹ì • í´ë˜ìŠ¤ $i$ì˜ True Positive, False Positive, False Negative ì´ê³  $N$ì€ í´ë˜ìŠ¤ì˜ ê°¯ìˆ˜ì´ë‹¤.

$$ {IoU}_i = \left( \frac{TP_i}{FP_i + FN_i + TP_i} \right) $$

$$ mIoU = \sum_{i=1}^N \left( \frac{IoU_i}{N} \right ) $$

## 4.2. Implementation Details

ëŒ€ë¶€ë¶„ì˜ UDA SOTA ëª¨ë¸ì€ Resnet101ì„ backboneìœ¼ë¡œ í•œ DeepLab v2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  source ë„ë©”ì¸ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆëŠ” (1280, 620), target ë„ë©”ì¸ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆëŠ” (1024, 512)ë¥¼ ì‚¬ìš©í•œë‹¤. ì•„ë˜ ì‹¤í—˜ì—ì„œëŠ” GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ëª¨ë¸ì€ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ë‚˜ source ë„ë©”ì¸ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆëŠ” (640, 360), target ë„ë©”ì¸ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆëŠ” (640, 360)ìœ¼ë¡œ resize í•˜ì—¬ ì‹¤í—˜í•œë‹¤.

### 4.2.1. Semantic Segmentation

ìš°ì„  ì¼ë°˜ì ì¸ Supervised-learning ë°©ì‹ì˜ Semantic segmentation ëª¨ë¸ê³¼ì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•´ SOTA ëª¨ë¸ì¸ FCNê³¼ DeepLab v3+ ì„±ëŠ¥ ë¹„êµë¥¼ ìˆ˜í–‰í•˜ì˜€ë‹¤. Backboneì€ ë™ì¼í•˜ê²Œ Resnet-50ìœ¼ë¡œ ì„¤ì •í•˜ì˜€ê³  Cityscapesì˜ Labeled ì´ë¯¸ì§€ë“¤ë¡œ Supervised-learning ë°©ì‹ìœ¼ë¡œ í•™ìŠµì‹œì¼°ë‹¤.

![](/assets/images/21-09-24-paper-sl-learning-result.png)

|    model    | road | sidewalk | building | wall | fence | pole | traffic light | traffic sign | vegetation | terrain | sky  | person | rider | car  | truck | bus  | train | motorcycle | bicycle | Pixel Accuracy | mIoU  |
| :---------: | :--: | :------: | :------: | :--: | :---: | :--: | :-----------: | :----------: | :--------: | :-----: | :--: | :----: | :---: | :--: | :---: | :--: | :---: | :--------: | :-----: | :------------: | :---: |
|     FCN     | 0.97 |   0.81   |   0.9    | 0.26 | 0.45  | 0.54 |     0.67      |     0.75     |    0.91    |  0.53   | 0.93 |  0.78  | 0.57  | 0.93 | 0.48  | 0.7  | 0.36  |    0.56    |  0.75   |     94.693     | 68.03 |
| DeepLab v3+ | 0.98 |   0.84   |   0.92   | 0.56 | 0.59  | 0.64 |      0.7      |     0.78     |    0.92    |  0.64   | 0.95 |  0.81  | 0.63  | 0.94 | 0.69  | 0.76 | 0.43  |    0.63    |  0.76   |     95.826     | 74.97 |

ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ê³¼ Backboneì— ë”°ë¼ mIoU ê°’ ì°¨ì´ê°€ ìˆìœ¼ë‚˜, Supervised learningìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼°ì„ ë•Œ mIoUê°€ ì•½ 70 ì •ë„ ë‚˜ì˜¤ëŠ” ê²ƒìœ¼ë¡œ í™•ì¸í–ˆë‹¤. 

ë§ì€ domain adaptation ë…¼ë¬¸ë“¤ì´ Resnet101ì„ backboneìœ¼ë¡œ í•œ DeepLab v2ë¥¼ Semantic segmentation ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ê³  ìˆê¸° ë•Œë¬¸ì—, ë™ë“±í•œ ë¹„êµë¥¼ ìœ„í•´ ì´í›„ ì‹¤í—˜ì—ì„œëŠ” Atrous Spatial Pyramid Pooling(ASPP) ëª¨ë“ˆì„ í¬í•¨í•œ DeepLab v2 ëª¨ë¸ì„ task ëª¨ë¸ë¡œ ì„¤ì •í•˜ì—¬ ì§„í–‰í•œë‹¤. Cityscapes ë°ì´í„°ì…‹ì„ ì´ìš©í•´ í•™ìŠµí•œ Resnet101 + DeepLab v2 ëª¨ë¸ì˜ ê¸°ë³¸ ì„±ëŠ¥ì€ ì•„ë˜ì™€ ê°™ë‹¤.

| Model                  | road | walk | build. | wall | fence | pole | light | sign | vege. | terr. | sky  | persn | rider | car  | truck | bus | train | mcyc | Bike | mIoU |
| :--------------------- | :--- | :--- | :----- | :--- | :---- | :--- | :---- | :--- | :---- | :---- | :--- | :---- | :---- | :--- | :---- | :-- | :---- | :--- | :--- | :--- |
| DeepLab v2 (Resnet101) | 96.7 | 76.2 | 88.6   | 47.2 | 47.6  | 45.1 | 57.9  | 67.6 | 89.1  | 58.2  | 90.4 | 70    | 54.8  | 92.2 | 71.8  | 78  | 56.6  | 56.7 | 67.8 | 69.1 |

### 4.2.2. Style Transfer

Source ì´ë¯¸ì§€ì—ì„œ Target ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ë¡œ ì¬ìƒì„±ëœ ë°ì´í„°ê°€ domain gapì„ ì¤„ì´ëŠ”ë° ì–¼ë§ˆë‚˜ ê¸°ì—¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ì‹¤í—˜ìœ¼ë¡œ, ë™ì¼í•œ ëª¨ë¸ì„ GTA ë°ì´í„°ì™€, Cityscapes ìŠ¤íƒ€ì¼ë¡œ ì¬ìƒì„±ëœ GTA->Cityscapes ë°ì´í„°ì— ì ìš©í–ˆì„ ë•Œ mIoUë¥¼ ë¹„êµí•œë‹¤.

![](/assets/images/21-09-24-paper-style-transfer.png)

GTA ì´ë¯¸ì§€ì™€ Cityscapes ì´ë¯¸ì§€ ê°„ì˜ ì‹œê°ì  ì°¨ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•´ Labeled ë°ì´í„° ì—†ì´ Cityscapes ì´ë¯¸ì§€ì™€ GTA ì´ë¯¸ì§€ë§Œì„ ì´ìš©í•˜ì—¬ CycleGANì„ í•™ìŠµí•˜ê³ , GTAì´ë¯¸ì§€ë¥¼ Cityscapes ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¡œ ì¬ìƒì„±í•œ ê²°ê³¼ì´ë‹¤.

![](/assets/images/21-09-24-paper-style-transfer-prediction.png)

4.2.1ì¥ì—ì„œ Cityscapes ë°ì´í„°ë¡œë§Œ í•™ìŠµì‹œí‚¨ DeepLab v3+ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ GTA ìƒ˜í”Œê³¼ GTA->Cityscapes ìƒ˜í”Œì— ê°ê° ì˜ˆì¸¡í•œ ê²°ê³¼ì´ë‹¤. 

GTA5 ìƒ˜í”Œì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ëŠ” Cityscapesì™€ GTA5ì˜ ë°ì´í„° ìì²´ì˜ domain gapì— ì˜í•´ Cityscapes ë°ì´í„°ì— ì ìš©í–ˆì„ ë•Œ ë³´ë‹¤ ë” ë§ì€ ì˜ˆì¸¡ ì˜¤ì°¨ê°€ ë°œìƒí•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ë°˜ë©´ì— GTA5->Cityscapes ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•œ ê²°ê³¼ëŠ” GTA5 ë°ì´í„°ì— ë¹„í•´ ì ì€ ì˜¤ì°¨ë¥¼ ë³´ì´ê³  ìˆë‹¤.

| Data             | road | walk | building | wall | fence | pole | light | sign | vege. | terrain | sky  | person | rider | car  | truck | bus  | train | mCycle | bicycle | mIoU |
| :--------------- | :--- | :--- | :------- | :--- | :---- | :--- | :---- | :--- | :---- | :------ | :--- | :----- | :---- | :--- | :---- | :--- | :---- | :----- | :------ | :--- |
| GTA              | 70.2 | 19.3 | 60.4     | 23.3 | 13.4  | 25.3 | 31.8  | 17   | 53.5  | 24.3    | 85.6 | 41.2   | 1.7   | 55.4 | 19.1  | 16.8 | 2.4   | 6.4    | 5.4     | 30.1 |
| GTA â†’ Cityscapes | 80.7 | 26.8 | 6.76     | 29.3 | 13.6  | 30.8 | 26.2  | 21.1 | 61.2  | 33.5    | 76.2 | 47.6   | 27    | 63   | 37.1  | 15.8 | 4.9   | 18.2   | 7.4     | 36.2 |
| Cityscapes       | 98   | 84.5 | 92.3     | 56   | 59.1  | 64.6 | 70.2  | 78.9 | 92.4  | 64      | 95   | 81.6   | 63.2  | 94.7 | 69    | 76.9 | 43.3  | 63.4   | 76.5    | 74.9 |

í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•œ ë°ì´í„°ì˜ ê°¯ìˆ˜ëŠ” 24,966ë¡œ ë™ì¼í•˜ê²Œ ì„¤ì •í•˜ì—¬ mIoUë¥¼ ë¹„êµí–ˆì„ ë•Œ, GTA5 ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì— ë¹„í•´ generative ëª¨ë¸ì„ í†µí•´ GTAïƒ Cityscapes ìŠ¤íƒ€ì¼ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ ë°ì´í„°ë¡œ ì‚¬ìš©í–ˆì„ ë•Œ mIoUê°€ +6% ì¦ê°€í•˜ì˜€ê³ , ì´ì— ë”°ë¼ target domainê³¼ì˜ gapì´ ì¼ë¶€ ê°ì†Œí•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

![](/assets/images/21-09-24-paper-2021-11-04-15-20-27.png)

Style transfer ëª¨ë“ˆê³¼ UDA ëª¨ë“ˆì„ end-to-endë¡œ í•™ìŠµì‹œí‚¤ë©´ ìˆ˜ë ´í•˜ê¸°ê°€ ë” ì–´ë ¤ì›Œì§€ê¸° ë•Œë¬¸ì— GTAïƒ Cityscapes ë°ì´í„°ë¥¼ GTA ë°ì´í„° ëŒ€ì‹  source ë„ë©”ì¸ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ìš©í•œë‹¤.

### 4.2.3. Combined Augmentation

![](/assets/images/21-09-24-paper-combined-augmentation.png)

ê·¸ë¦¼7ì€ Cityscapes ì´ë¯¸ì§€ì™€ GTAïƒ Cityscapes ì´ë¯¸ì§€ë¥¼ í˜¼í•©í•˜ê¸° ìœ„í•˜ì—¬ ì„ì˜ ì‚¬ì´ì¦ˆì˜ Maskë¥¼ ë§Œë“¤ì–´ íŠ¹ì • ì˜ì—­ì„ ì¶”ì¶œí•´ë‚´ê³ , ë‹¤ë¥¸ ì´ë¯¸ì§€ì— ê²°í•©í•˜ì—¬ ë§Œë“  ìƒˆë¡œìš´ ì…ë ¥ ë°ì´í„°ì´ë‹¤. í•´ë‹¹ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë´¤ì„ ë•Œ ì´ë¯¸ì§€ê°€ ì–´ìƒ‰í•˜ê²Œ ê²°í•©ì´ ë˜ì–´ ìˆë”ë¼ë„ ëª¨ë¸ì´ ì¼ë°˜í™” ë˜ì–´ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì— í° ì˜¤ì°¨ ì—†ì´ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

ì‹œê°ì ì¸ ë¶€ë¶„ì—ì„œ í•œë‹¨ê³„ domain gapì„ ì¤„ì˜€ì§€ë§Œ ì™¸ê´€ìƒìœ¼ë¡œ ë³´ì´ëŠ” gap ì´ì™¸ì—ë„ ì‹¤ì œë¡œ ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ë³´ì´ì§€ ì•ŠëŠ” êµ¬ì¡°ì ì¸ ë¶€ë¶„ ë˜í•œ í•™ìŠµí•´ì•¼ í•  í•„ìš”ê°€ ìˆë‹¤. ì´ë¥¼ ìœ„í•´ ë„ë©”ì¸ì„ í˜¼í•©í•œ cutmix ë°ì´í„°ë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ êµ¬ì¡°ì ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•˜ì˜€ê³ , ì´ëŠ” domain confusionì„ ì•¼ê¸°í•˜ì—¬ ë„ë©”ì¸ ì§€ì‹ê³¼ ê´€ê³„ì—†ì´ taskì— ì§‘ì¤‘í•˜ì—¬ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.

### 4.2.4. Pseudo Labeling

![](/assets/images/21-09-24-paper-pseudo-labeling-result.png)

K=3ìœ¼ë¡œ ì„¤ì •í•˜ê³  Unlabeled target ë°ì´í„°ì— ëŒ€í•´augmentation ë°ì´í„°ì™€ ì˜ˆì¸¡ê°’ì˜ confidence mapì„ ì–»ì–´ë‚´ê³ , maximum confidence mapê³¼ confidence-based maskingì„ í†µí•´ ë§Œë“¤ì–´ì§„ pseudo-labeling ê³¼ì •ì´ë‹¤. Augmentationì€ AutoAugment [20]ë¥¼ ì‚¬ìš©í–ˆë‹¤. 

![](/assets/images/21-09-24-paper-pseudo-labeling-data.png)

ì´ë ‡ê²Œ ìƒì„±ëœ pseudo-labeling ë°ì´í„°ë“¤ì„ ì´ìš©í•´ student segmentation ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤.

## 4.3. Quantitative Comparison

### 4.3.1. Performance

![](/assets/images/21-09-24-paper-performance.png)

DAì™€ SSL ê¸°ë²•ë“¤ì´ ì ìš©ë¨ì— ë”°ë¼ Target ë„ë©”ì¸ì¸ Cityscapes ë°ì´í„° ëŒ€ìƒìœ¼ë¡œ semantic segmentationì˜ˆì¸¡ì„ í–ˆì„ ë•Œ ê²°ê³¼ê°€ ì¢‹ì•„ì§ì„ ë³¼ ìˆ˜ ìˆë‹¤. 
Domain shiftì— ëŒ€í•œ ê³ ë ¤ì—†ì´ ì§ì ‘ì ìœ¼ë¡œ ì˜ˆì¸¡í–ˆì„ ë•Œ, ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ê´€ê³„ì—†ì´ ë§ì€ ì˜¤ì°¨ê°€ ë°œìƒí•œë‹¤. 
Style Transferë¥¼ ì ìš©í•œ ë°ì´í„°ì—ëŠ” ì–´ëŠ ì •ë„ semantic êµ¬ì¡°ë¥¼ íŒŒì•…í•œ ê²ƒì²˜ëŸ¼ ë³´ì´ì§€ë§Œ ì—¬ì „íˆ ë§ì€ ë…¸ì´ì¦ˆê°€ ìˆë‹¤. 
Style Transfer ë°ì´í„°ë¥¼ source ë°ì´í„°ë¡œ í•˜ì—¬ UDAë¥¼ ì ìš©í•œ ëª¨ë¸ì€ ì¼ë°˜ì ì¸ UDA SOTA ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆë‹¤. 
ì•½ê°„ì˜ Labeled target ë°ì´í„°ê°€ ìˆë‹¤ëŠ” ê°€ì •í•˜ì— SSL ëª¨ë“ˆì„ ë„ì…í•˜ê²Œ ë˜ë©´ target ë„ë©”ì¸ì— ëŒ€í•œ ì •ë³´ë“¤ì„ í† ëŒ€ë¡œ ì„±ëŠ¥ì´ í›¨ì”¬ í–¥ìƒëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. 

| Model               | road | walk | building | wall | fence | pole | light | sign | vege. | terrain | sky  | person | rider | car  | truck | bus  | train | mCycle | bicycle | mIoU |
| :------------------ | :--- | :--- | :------- | :--- | :---- | :--- | :---- | :--- | :---- | :------ | :--- | :----- | :---- | :--- | :---- | :--- | :---- | :----- | :------ | :--- |
| No Adaptation       | 83.9 | 10.2 | 74.3     | 4.4  | 3     | 10.3 | 11.8  | 11.4 | 84.2  | 15.8    | 68.7 | 39     | 0.1   | 79.1 | 26.1  | 17.3 | 0     | 2.7    | 0       | 28.5 |
| ST (Style Transfer) | 75.7 | 16.7 | 77.2     | 12.5 | 21    | 25.4 | 30    | 20.1 | 81.3  | 24.6    | 70.3 | 53.7   | 26.4  | 49.9 | 17.1  | 25.8 | 6.4   | 25.2   | 36      | 36.6 |
| ST + UDA            | 89.4 | 26.2 | 82.7     | 25.8 | 22.9  | 36.1 | 40.4  | 38.8 | 84.1  | 37.5    | 83.5 | 59     | 26.7  | 83.6 | 28.5  | 36.6 | 0.1   | 14.6   | 26.7    | 44.4 |
| ST + UDA + SSL      | 94.7 | 67.6 | 83.6     | 38.2 | 27.9  | 41.6 | 44.7  | 50   | 84.4  | 41.9    | 86.2 | 66.2   | 43.8  | 89.5 | 68.6  | 52.8 | 36.3  | 39.2   | 53.1    | 58.4 |

ê° ë‹¨ê³„ì— ëŒ€í•œ í´ë˜ìŠ¤ ë³„ IoUì™€ mIoUëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. SSLì„ ë„ì…í•œ í›„ ê¸‰ê²©í•˜ê²Œ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆê³ , Knowledge Distillationë¥¼ ì¶”ê°€í•˜ì—¬ ë¶ˆí™•ì‹¤í•œ ì •ë³´ë¡œ Supervised learningì„ ìˆ˜í–‰í•˜ë”ë¼ë„ ì„±ëŠ¥ì´ ìƒìŠ¹í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

| Model           | road | walk | building | wall | fence | pole | light | sign | vege. | terrain | sky  | person | rider | car  | truck | bus  | train | mCycle | bicycle | mIoU |
| :-------------- | :--- | :--- | :------- | :--- | :---- | :--- | :---- | :--- | :---- | :------ | :--- | :----- | :---- | :--- | :---- | :--- | :---- | :----- | :------ | :--- |
| Cycada          | 79.1 | 33.1 | 77.9     | 23.4 | 17.3  | 32.1 | 33.3  | 31.8 | 81.5  | 26.7    | 69   | 62.8   | 14.7  | 74.5 | 20.9  | 25.6 | 6.9   | 18.8   | 20.4    | 39.5 |
| AdaptSegNet     | 86.5 | 36   | 79.9     | 23.4 | 23.3  | 23.9 | 35.2  | 14.8 | 83.4  | 33.3    | 75.6 | 58.5   | 27.6  | 73.7 | 32.5  | 35.4 | 3.9   | 30.1   | 28.1    | 42.4 |
| AdvEnt          | 89.4 | 33.1 | 81       | 26.6 | 26.8  | 27.2 | 33.5  | 24.7 | 83.9  | 36.7    | 78.8 | 58.7   | 30.5  | 84.8 | 38.5  | 44.5 | 1.7   | 31.6   | 32.4    | 45.5 |
| Seg-Uncertainty | 90.5 | 35   | 84.6     | 34.3 | 24    | 36.8 | 44.1  | 42.7 | 84.5  | 33.6    | 82.5 | 63.1   | 34.4  | 85.8 | 32.9  | 38.2 | 2     | 27.1   | 41.8    | 48.3 |
| Ours            | 94.7 | 67.6 | 83.6     | 38.2 | 27.9  | 41.6 | 44.7  | 50   | 84.4  | 41.9    | 86.2 | 66.2   | 43.8  | 89.5 | 68.6  | 52.8 | 36.3  | 39.2   | 53.1    | 58.4 |

UDA SOTA ëª¨ë¸ë“¤ê³¼ í´ë˜ìŠ¤ ë³„ IoUì™€ mIoUë¥¼ ë¹„êµí•œ ê²°ê³¼ì´ë‹¤. UDAS ëª¨ë¸ì´ ì›”ë“±í•˜ê²Œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ê³ ìˆë‹¤. 

### 4.3.2. Data Dependency

Supervised Learning(SL) ë°©ë²•ë¡ ì˜ ê²½ìš° í•™ìŠµì„ ìœ„í•´ì„œëŠ” ë§ì€ ì–‘ì˜ Labeled ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤. ì ì€ labeled ë°ì´í„°ë¡œ í•™ìŠµì‹œí‚¤ê²Œ ë˜ë©´ í•™ìŠµ ë°ì´í„°ì— overfitting ë˜ëŠ” ê²½í–¥ì´ ìˆë‹¤. ë°ì´í„°ê°€ ì ì€ ìƒí™©ì—ì„œ ì œì•ˆ ëª¨ë¸ì´ SL ë°©ë²•ì— ë¹„í•´ ì–¼ë§ˆë‚˜ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì´ëŠ”ì§€ ë¹„êµí•˜ê¸° ìœ„í•œ Data Dependencyì‹¤í—˜ì´ë‹¤.

Labeled target ì´ë¯¸ì§€ëŠ” Cityscapes ë°ì´í„°ì´ê³ , ì´ labeled ë°ì´í„° 2,979ì¥ì„ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí–ˆì„ ë•Œì™€ labeled í•™ìŠµ ë°ì´í„° ì–‘ì„ 1000, 500, 100, 0ìœ¼ë¡œ ê°ì†Œì‹œí‚¤ë©° mIoUë¥¼ ë¹„êµí•œ ê²°ê³¼ì´ë‹¤. 

| Model | 2975 | 1000         | 500           | 100           | 0             |
| :---- | :--- | :----------- | :------------ | :------------ | :------------ |
| SL    | 69.1 | 61.2 (-7.9%) | 55.4 (-13.7%) | 41.6 (-27.5%) | -             |
| UDAS  | 56.4 | 51.9 (-4.5%) | 52.8 (-3.6%)  | 49.2 (-7.2%)  | 43.9 (-12.5%) |

Labeled target ì´ë¯¸ì§€ê°€ 2975ì¥ì¸ ê²½ìš° UDASëª¨ë¸ì´ -12.7% ì˜ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆê³ , 1000ì¥ì¸ ê²½ìš° -9.3%, 500ì¥ì¸ ê²½ìš° -2.6%, ê·¸ë¦¬ê³  100ì¥ì¸ ê²½ìš° +7.6%ë¡œ, labeled target ë°ì´í„°ê°€ ì ì–´ì§ˆ ìˆ˜ë¡ UDASê°€ SL ë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

![](/assets/images/21-09-24-paper-udas-sl.png)

Labeled target ì´ë¯¸ì§€ì— ë”°ë¥¸ mIoUë¥¼ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•œ ê²ƒì´ë‹¤. SL ëª¨ë¸ì€ labeled ë°ì´í„°ì–‘ì´ ì ì–´ì§ì— ë”°ë¼ ê¸‰ê²©í•˜ê²Œ ì„±ëŠ¥ì´ í•˜ë½í•˜ì§€ë§Œ UDAS ëª¨ë¸ì€ labeled ë°ì´í„°ì–‘ì´ ì ì–´ì§€ë”ë¼ë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ë¥¼ í†µí•´ ì œì•ˆí•œ UDAS ëª¨ë¸ì´ ë„ë©”ì¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ë‚®ì•„ì¡Œë‹¤ê³  ë¯¸ë£¨ì–´ ì§ì‘í•´ë³¼ ìˆ˜ ìˆë‹¤.

ë¬´ì—‡ë³´ë‹¤ ë°ì´í„°ê°€ ì „í˜€ ì¡´ì¬í•˜ëŠ” ì•ŠëŠ” ê²½ìš°, ì œì•ˆ ëª¨ë¸ì´ Source ë„ë©”ì¸ ë°ì´í„°ë§Œìœ¼ë¡œ adaptation í•˜ëŠ” UDA êµ¬ì¡°ë¡œ ë™ì‘í•˜ê¸° ë•Œë¬¸ì— labeled ë°ì´í„° ì—†ì´ëŠ” ë¬´ìš©ì§€ë¬¼ì´ ë˜ëŠ” SL ëª¨ë¸ì— ë¹„í•´ ê²½ìŸë ¥ ìˆë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.

# 5. ê²°ë¡ 

AI í•™ìŠµì— ìˆì–´ì„œ í•­ìƒ í° ì¥ì• ë¬¼ì´ ë˜ëŠ” ë°ì´í„° ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤. ì»´í“¨í„° ê·¸ë˜í”½ì´ ë°œì „í•¨ì— ë”°ë¼ ì ì°¨ì ìœ¼ë¡œ í˜„ì‹¤ì„¸ê³„ì™€ ê°€ìƒì„¸ê³„ì˜ ì‹œê°ì  ê²½ê³„ê°€ ëª¨í˜¸í•´ì§€ê³  ìˆê¸° ë•Œë¬¸ì—, ë¬´í•œí•œ ë°ì´í„°ë¥¼ ì°½ì¶œí•´ë‚¼ ìˆ˜ ìˆëŠ” synthetic ë°ì´í„°ì— ëŒ€í•œ í™œìš©ë„ê°€ ë†’ì•„ì§ˆ ê²ƒì´ë‹¤. ë˜í•œ AIëª¨ë¸ì´ ì»¤ì§€ë©´ì„œ ì ì  ë” ë§ì€ ë°ì´í„°ê°€ ìš”êµ¬ë˜ëŠ”ë° í•­ìƒ ë°ì´í„°ì— ì˜ì¡´ì ì¸ AI ëª¨ë¸ì—ì„œ ë²—ì–´ë‚˜ ìŠ¤ìŠ¤ë¡œ ê·œì¹™ì„ ì°¾ì•„ë‚´ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³ ì í–ˆë‹¤. 

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Syntheticë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ UDAì™€ SSLì„ ê²°í•©í•œ êµ¬ì¡°ë¥¼ ì œì•ˆí•˜ì˜€ê³  semantic segmentation ë¬¸ì œì— ë§ëŠ” augmentation, pseudo-labeling ê¸°ë²•ì„ ì¶”ê°€í•˜ì—¬ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ìƒí™©ì—ì„œë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. 

UDA ë°©ë²•ë¡ ê³¼ synthetic ë°ì´í„°ì˜ ì§ˆì´ í–¥ìƒí•¨ì— ë”°ë¼ ì œì•ˆí•œ UDAS êµ¬ì¡°ì˜ ì„±ëŠ¥ì€ ê·¸ì™€ ë¹„ë¡€í•˜ì—¬ í–¥ìƒë  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•œë‹¤.

# 6. ì°¸ê³  ë¬¸í—Œ

[1] Long, Jonathan, Evan Shelhamer, and Trevor Darrell. "Fully convolutional networks for semantic segmentation."Â Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.
[2] Zhao, Hengshuang, et al. "Pyramid scene parsing network."Â Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.
[3] Yu, Fisher, Vladlen Koltun, and Thomas Funkhouser. "Dilated residual networks."Â Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.
[4] Chen, Liang-Chieh, et al. "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs."Â IEEE transactions on pattern analysis and machine intelligenceÂ 40.4 (2017): 834-848.
[5] Tzeng, Eric, et al. "Adversarial discriminative domain adaptation."Â Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.
[6] Hoffman, Judy, et al. "Cycada: Cycle-consistent adversarial domain adaptation."Â International conference on machine learning. PMLR, 2018.
[7] Tsai, Yi-Hsuan, et al. "Learning to adapt structured output space for semantic segmentation."Â Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.
[8] Xie, Qizhe, et al. "Self-training with noisy student improves imagenet classification."Â Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.
[9] Pham, Hieu, et al. "Meta pseudo labels."Â Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.
[10] Miyato, Takeru, et al. "Virtual adversarial training: a regularization method for supervised and semi-supervised learning."Â IEEE transactions on pattern analysis and machine intelligenceÂ 41.8 (2018): 1979-1993.
[11] Xie, Qizhe, et al. "Unsupervised data augmentation for consistency training."Â arXiv preprint arXiv:1904.12848Â (2019).
[12] Berthelot, David, et al. "Mixmatch: A holistic approach to semi-supervised learning."Â arXiv preprint arXiv:1905.02249Â (2019).
[13] Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence."Â arXiv preprint arXiv:2001.07685Â (2020).
[14] Yun, Sangdoo, et al. "Cutmix: Regularization strategy to train strong classifiers with localizable features."Â Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.
[15] Tremblay, Jonathan, et al. "Training deep networks with synthetic data: Bridging the reality gap by domain randomization."Â Proceedings of the IEEE conference on computer vision and pattern recognition workshops. 2018.
[16] Kar, Amlan, et al. "Meta-sim: Learning to generate synthetic datasets."Â Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.
[17] Andrychowicz, OpenAI: Marcin, et al. "Learning dexterous in-hand manipulation."Â The International Journal of Robotics ResearchÂ 39.1 (2020): 3-20.
[18] Cordts, Marius, et al. "The cityscapes dataset for semantic urban scene understanding."Â Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.
[19] Richter, Stephan R., et al. "Playing for data: Ground truth from computer games."Â European conference on computer vision. Springer, Cham, 2016.
[20] Cubuk, Ekin D., et al. "Autoaugment: Learning augmentation strategies from data."Â Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.

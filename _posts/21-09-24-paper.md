---
title: ğŸ’¡ Paper
tags: paper ğŸ’¡ ğŸ”¥
mathjax_autoNumber: false
article_header:
    type: overlay
    theme: dark
    background_color: "#123"
    background_image: false
cover: /assets/images/21-09-24-paper-2021-09-25-00-56-13.png
---

Self-supervised learning with image based synthetic teacher model   
(ì´ë¯¸ì§€ ê¸°ë°˜ì˜ ê°€ìƒ êµì‚¬ ëª¨ë¸ì„ ì´ìš©í•œ ìê¸° ì§€ë„ í•™ìŠµ)

<!--more-->

- ê°ì‚¬ì˜ ê¸€
- ëª©ì°¨
- ê·¸ë¦¼ ëª©ì°¨
- í‘œ ëª©ì°¨

# êµ­ë¬¸ ìš”ì•½ / ì˜ë¬¸ ìš”ì•½

> 2ìª½ ì´ë‚´

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” synthetic ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ë©”ì¸ í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì˜ì¡´ì„±ì„ ê°ì†Œì‹œí‚¤ëŠ” ë™ì‹œì— task lossë¥¼ ìµœì†Œí™” í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì— ëŒ€í•´ ì—°êµ¬í•˜ê³ ì í•œë‹¤.

UDAì™€ SSLì„ ê²°í•©

- í•µì‹¬ì–´: Unsupervised Domain Adaptation, Semi-supervised learning, Self-training, Pseudo-Labeling, Synthetic data

# 1. ì—°êµ¬ ë°°ê²½

ImageNetì˜ ë°ì´í„° ê³µê°œë¥¼ ì‹œì‘ìœ¼ë¡œ Data-driven ê¸°ë°˜ì˜ Supervised learningì´ ì—¬ëŸ¬ visual task ë¶„ì•¼ì—ì„œ ì¢‹ì€ ì„±ê³¼ë¥¼ ê±°ë’€ë‹¤. ê²€ì¦ëœ ì¢‹ì€ ëª¨ë¸ë“¤ì´ ì´ë¯¸ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì—, íŠ¹ì • ë¬¸ì œì— ë§ëŠ” AIëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ê·¸ì— ë§ëŠ” ì–‘ì§ˆì˜ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ë§ì´ í™•ë³´í•˜ëŠëƒê°€ ê²°êµ­ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢Œìš°í•˜ê²Œ ë˜ì—ˆë‹¤.

í•˜ì§€ë§Œ íŠ¹ì • ë„ë©”ì¸ì˜ taskì— ë§ëŠ” ë°ì´í„°ë¥¼ í™•ë³´í•˜ê³ , ê·¸ ë°ì´í„°ì— labeling í•˜ëŠ” ê²ƒì€ ë§ì€ ì‹œê°„ê³¼ ë¹„ìš©ì„ í•„ìš”ë¡œ í•œë‹¤. ì´ëŸ¬í•œ ë°ì´í„° ì˜ì¡´ì ì¸ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë”ë¼ë„ íš¨ê³¼ì ì¸ í•™ìŠµì„ í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì—°êµ¬ë“¤ì´ ì§„í–‰ë˜ê³  ìˆë‹¤. ìœ ì‚¬í•œ taskì—ì„œ í•™ìŠµëœ pretrain ëª¨ë¸ì„ ê°€ì ¸ì™€ target taskì— ì ìš©í•˜ëŠ” Transfer Learning, Domain Adaptation, ê·¸ë¦¬ê³  labeled dataê°€ ì ê±°ë‚˜ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” Semi-Supervised Learning, Self-Supervised Learning ë“±ì˜ ì—°êµ¬ë“¤ì´ ìˆë‹¤.

![ììœ¨ì£¼í–‰ì°¨ëŸ‰, ë¡œë³´í‹±ìŠ¤ ë¶„ì•¼ì—ì„œì˜ synthetic ë°ì´í„°](/assets/images/21-09-24-paper-autonomous-synthetic-data.png)

Labeling ì‘ì—…ì˜ ë¹„ìš©ì´ í° ë¬¸ì œë„ ìˆì§€ë§Œ íŠ¹ì • ìƒí™©ì— ëŒ€í•œ ë°ì´í„° ìì²´ë¥¼ ì–»ê¸° ì–´ë ¤ìš´ ê²½ìš°ë„ ìˆë‹¤. íŠ¹íˆë‚˜ ììœ¨ì£¼í–‰ì°¨ëŸ‰, ë¡œë³´í‹±ìŠ¤ ë¶„ì•¼ì—ì„œëŠ” í˜„ì‹¤ ì„¸ê³„ì—ì„œ ì–»ê¸° ì–´ë ¤ìš´ ë°ì´í„°ë“¤ì´ ì¡´ì¬í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ êµì°¨ë¡œ í•œê°€ìš´ë°ì— ì‚¬ëŒì´ ìˆëŠ” ë°ì´í„°ë‚˜, ë¡œë´‡ì˜ ì¹´ë©”ë¼ ì‹œì ì—ì„œì˜ ë°ì´í„° ë“±ì€ ì‰½ê²Œ íšë“í•  ìˆ˜ê°€ ì—†ì„ ê²ƒì´ë‹¤.

ì´ ê²½ìš° ì‹¤ì œ ì„¸ê³„ë¥¼ digital twin í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” ë°©ì•ˆì´ ìˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ì„ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ í˜„ì‹¤ ì„¸ê³„ì—ì„œ ì¬í˜„í•  ìˆ˜ ì—†ëŠ” ìƒí™©ë“¤ì„ ì—°ì¶œí•˜ê³  í™˜ê²½ì„ ììœ ìì¬ë¡œ ë³€ê²½í•˜ì—¬ ë°ì´í„°ë“¤ì„ ì¶”ì¶œí•  ìˆ˜ê°€ ìˆë‹¤. ì»´í“¨í„° ê·¸ë˜í”½ì— ì˜í•´ RGB ì´ë¯¸ì§€, depth ë°ì´í„°, ê°ì²´ì˜ bounding box, pixel ë³„ class, optical flow ë“±ì˜ ì •í™•í•œ Ground Truth ë°ì´í„°ë“¤ì´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ synthetic ë°ì´í„°ë¥¼ ì´ìš©í•´ AI í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

Synthetic ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ í•™ìŠµí•œ ëª¨ë¸ì´ í˜„ì‹¤ ì„¸ê³„ì—ì„œ ì˜ ë™ì‘í•˜ê¸° ìœ„í•´ì„œëŠ” ì‹¤ì œ ì„¸ê³„ì™€ ì‹œë®¬ë ˆì´ì…˜ ê°„ì˜ ê²©ì°¨ê°€ ì‘ì•„ì•¼ë§Œ í•œë‹¤. í•˜ì§€ë§Œ ì‹œë®¬ë ˆì´ì…˜ì„ ìµœëŒ€í•œ ì‚¬ì‹¤ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ë§ì€ ë…¸ë ¥ì´ ë“¤ì–´ê°€ê³ , ì‹¤ì œ ì„¸ê³„ì˜ ëª¨ë“  ë°ì´í„°ë“¤ì„ ì •ëŸ‰ì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ê¸°ì—ëŠ” ì‰½ì§€ ì•Šì€ ì¼ì´ë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” synthetic ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ë©”ì¸ í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì˜ì¡´ì„±ì„ ê°ì†Œì‹œí‚¤ëŠ” ë™ì‹œì— ì‹¤ì œ ì„¸ê³„ì—ì„œë„ ì˜ ë™ì‘í•  ìˆ˜ ìˆë„ë¡ task lossë¥¼ ìµœì†Œí™” í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì— ëŒ€í•´ ì—°êµ¬í•˜ê³ ì í•œë‹¤.

# 2. ì„ í–‰ ì—°êµ¬

## 2.1. Semantic Segmentation

Semantic segmentation(SS) ëŠ” ì´ë¯¸ì§€ì˜ ê° í”½ì…€ì´ ì–´ëŠ í´ë˜ìŠ¤ì— ì†í•˜ëŠ” ì§€ ì˜ˆì¸¡í•˜ëŠ” ê²ƒìœ¼ë¡œ, ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ ì˜ë¯¸ì™€ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì—¬ ë” ê¹Šì´ ìˆê²Œ ì´í•´í•˜ëŠ” ì‘ì—…ì´ë‹¤. í”½ì…€ ìˆ˜ì¤€ì˜ ë ˆì´ë¸”ë§ì´ ìˆ˜í–‰ë˜ê¸° ë•Œë¬¸ì— dense labeling task ë¼ê³  ë¶ˆë¦¬ê³ , ì´ëŠ” classification ì´ë‚˜ localizationì— ë¹„í•´ ì–´ë ¤ìš´ ë¬¸ì œë¡œ ë¶„ë¥˜ëœë‹¤.

ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ê°€ ë‚˜ì˜¤ë©´ì„œ ì„±ëŠ¥ì´ ìƒë‹¹íˆ ê°œì„ ë˜ì—ˆëŠ”ë° ìµœê·¼ì—ëŠ” ì…ë ¥ ê³µê°„ ì°¨ì›ì„ ìœ ì§€í•˜ë©° ì „ì—­ì˜ semantic ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•´ encoder, decoderë¡œ êµ¬ì„±ëœ auto-encoder êµ¬ì¡°ê°€ ë§ì´ ì‚¬ìš©ë˜ê³  ìˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ FCN, PSPNet, DRN, DeepLab ë“±ê³¼ ê°™ì€ ì•„í‚¤í…ì²˜ë“¤ì´ ì œì•ˆë˜ì—ˆìœ¼ë©° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆë‹¤.

í•˜ì§€ë§Œ ëŒ€ëŸ‰ì˜ labeled ë°ì´í„°ì— ì˜ì¡´ì ì´ë¼ ë°ì´í„°ì…‹ì„ í™•ë³´í•˜ëŠ”ë°ì— ë§ì€ ì‹œê°„ì„ ë“¤ì—¬ì•¼í•œë‹¤. í”½ì…€ ë³„ë¡œ annotation í•˜ëŠ” ê²ƒì€ ë‹¤ë¥¸ visual task ì— ë¹„í•´ ë¹„ìš©ê³¼ ì‹œê°„ì´ ë§ì´ ì†Œìš”ë˜ê¸° ë•Œë¬¸ì— ì›í•˜ëŠ” ë„ë©”ì¸ì˜ ë°ì´í„°ë¥¼ ì–»ê¸°ê°€ ì‰½ì§€ ì•Šë‹¤.

ì´ì— ë”°ë¼ synthetic ë°ì´í„°ì— ëŒ€í•œ í™œìš©ì²˜ê°€ ë†’ì€ taskë¡œ ë¶„ë¥˜ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë³¸ ë…¼ë¬¸ì—ì„œëŠ” semantic segmentationì„ downstream taskë¡œ ì„¤ì •í•˜ì—¬ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ê³ ì í•œë‹¤. ì–‘ì´ ë§ê³  ì‰½ê²Œ ì–»ì„ ìˆ˜ ìˆëŠ” synthetic ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì§€ì‹ì„ ì¶”ì¶œí•˜ê³  ì´ë¥¼ í™œìš©í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ labeling í•˜ëŠ” ë°ì´í„°ì˜ ì–‘ì„ ì¤„ì´ê³ ì í•œë‹¤. 

## 2.3. Unsupervised Domain Adaptation

ì¼ë°˜ì ìœ¼ë¡œ Labeled ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ pre-trainedëœ í° ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ transfer learningì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì´ ìˆë‹¤. Transfer learningì„ í•˜ê¸° ìœ„í•´ì„œë„ í•´ë‹¹ ë„ë©”ì¸ì— ë§ëŠ” labeled ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ë§Œ Domain Adaptation(DA)ì€ ë‹¤ë¥¸ ë„ë©”ì¸(Source)ì—ì„œ ë°°ìš´ ì§€ì‹ì„ ì‚¬ìš©í•´ ìƒˆë¡œìš´ ë„ë©”ì¸(Target)ì˜ labeled ë°ì´í„°ê°€ ì—†ëŠ” ìƒí™©ì—ì„œë„ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ë‹¤. Zero-shot learning, few-shot learning, self-supervised learningê³¼ í•¨ê»˜ sample-efficient learningì˜ í•œ ìœ í˜•ì´ë‹¤.

![](/assets/images/21-09-24-paper-domain-adaptation.png)

Source ë„ë©”ì¸ê³¼ target ë„ë©”ì¸ ê°„ì˜ ë°ì´í„° ë¶„í¬ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— source ë„ë©”ì¸ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì„ target ë„ë©”ì¸ì— ì§ì ‘ì ìœ¼ë¡œ transfer í•˜ê²Œ ë˜ë©´ doamin shift(ë˜ëŠ” domain gap)ì™€ dataset biasì— ì˜í•´ ì˜¤ì°¨ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì´ ë•Œ Domain Adaptation ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ë©´ source ì™€ target ë°ì´í„° ë¶„í¬ë¥¼ ìœ ì‚¬í•˜ê²Œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. 

Unsupervised Domain Adaptation(UDA)ëŠ” Target ë„ë©”ì¸ì˜ unlabeled ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸ ë„ë©”ì¸ì˜ labeled ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ì¼ì¢…ì˜ Semi-supervised learningì˜ ë³€í˜•ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. Target ë„ë©”ì¸ì˜ labeled ë°ì´í„°ëŠ” í•„ìš”í•˜ì§€ ì•Šì§€ë§Œ ì¶©ë¶„í•œ ì–‘ì˜ Unlabeled target ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤.

![](/assets/images/21-09-24-paper-adaptation-level.png)

DA ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•œ ì£¼ìš” ì „ëµì€ source ë„ë©”ì¸ê³¼ target ë„ë©”ì¸ ì‚¬ì´ì˜ ê²©ì°¨ë¥¼ ì¤„ì„ìœ¼ë¡œì¨ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì„±ëŠ¥ ì €í•˜ë¥¼ ë§‰ëŠ” ë°©ë²•ì´ë‹¤. Input-level, feature-level, output-levelì—ì„œ ê°ê° adaptation ëª¨ë“ˆì„ ì¶”ê°€í•˜ì—¬ ë„ë©”ì¸ ê°„ ë¶ˆì¼ì¹˜ì„±ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.

Adversarial Discriminative Adaptation by Backpropagation(CVPR 2017)ëŠ” UDAì— GANì„ ë„ì…í•˜ì—¬ adversarial adaptationì„ ì²˜ìŒ ì œì•ˆí•œ ë…¼ë¬¸ìœ¼ë¡œ, featue levelì— domain discriminatorë¥¼ ì¶”ê°€í•˜ê³  adversarial lossë¥¼ ì‚¬ìš©í•˜ì—¬ domain discrepancyë¥¼ ìµœì†Œí™” í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí–ˆë‹¤. 

> feature levelì— adversarial learningì„ ë„ì…í•˜ì—¬, source, target ë„ë©”ì¸ ê°„ confusionì„ ìœ ë„í•œë‹¤. segmentation ëª¨ë¸ì„ source, targetì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ê³  feature extractorë¥¼ í†µí•´ ë‚˜ì˜¨ featureê°’ë“¤ì´ source ë„ë©”ì¸ì¸ì§€ target ë„ë©”ì¸ì¸ì§€ êµ¬ë¶„í•˜ê¸° ì–´ë µê²Œ í•™ìŠµì‹œí‚´ìœ¼ë¡œì¨ ë„ë©”ì¸ ë¶ˆì¼ì¹˜ì„±ì„ ì¤„ì´ë©° ë™ì‹œì— segmentation ëª¨ë¸ì´ í•™ìŠµë˜ë„ë¡ í–ˆë‹¤.

Cycle-Consistent Adversarial Domain Adaptation(ICML 2018)ì—ì„œëŠ” feature levelì— adversarial learningì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , input-levelì—ì„œ source ë„ë©”ì¸ ì´ë¯¸ì§€ë¥¼ target ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•˜ë„ë¡ generative ëª¨ë¸ì„ ë„ì…í•œ ë°©ë²•ì„ ì œì•ˆí–ˆë‹¤. Generative ëª¨ë¸ì„ ë„ì…í•¨ìœ¼ë¡œì¨ input ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ í™•ë¥ ë¶„í¬ë¥¼ ì°¾ì•„ë‚´ê³  ìœ ì‚¬í•œ í™•ë¥ ë¶„í¬ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•´ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤.

> Input levelì—ì„œì˜ domain gapì„ ì¤„ì´ê¸° ìœ„í•´ source ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ë¥¼ target ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•˜ë„ë¡ generative ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì´ ì‚¬ìš©ëœë‹¤. Generative ëª¨ë¸ì„ ë„ì…í•¨ìœ¼ë¡œì¨ input ë°ì´í„°ì— ëŒ€í•œ ìˆ¨ê²¨ì§„ í™•ë¥ ë¶„í¬ë¥¼ ì°¾ì•„ë‚´ê³ , ì´ì— discriminatorë¥¼ ë”í•´ domain confusionì„ ìœ ë„í•  ìˆ˜ ìˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ input-levelì˜ adaptation moduleì€ ìœ ì‚¬í•œ í™•ë¥ ë¶„í¬ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•´ ë‚´ëŠ” ë°ì— ëª©í‘œê°€ ìˆë‹¤. 

Learning to Adapted Structured Output space(CVPR 2018)ì—ì„œëŠ” ë‘ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ì´ ë‹¤ë¥´ë”ë¼ë„ segmentation ê²°ê³¼ì— í¬í•¨ë˜ì–´ ìˆëŠ” ê³µê°„ ë ˆì´ì•„ì›ƒ, local context ë“±ì˜ êµ¬ì¡°í™”ëœ íŠ¹ì„±ì€ ìœ ì‚¬í•˜ê¸° ë•Œë¬¸ì— ouput-levelì— adversarial learningì„ ë„ì…í•˜ì—¬ segmentation ì˜ˆì¸¡ ê²°ê³¼ distributionì„ ìœ ì‚¬í•˜ê²Œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí–ˆë‹¤.

![](/assets/images/21-09-24-paper-da-methods.png)

ì •ë¦¬í•˜ë©´ ê¸°ì¡´ì˜ UDAì—°êµ¬ëŠ” source ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ë¥¼ target ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•˜ê¸° ìœ„í•´ generative ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜, domain confusionì„ ìœ„í•´ discriminator ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, adversiarl learningì„ í†µí•´ ë‘ ë„ë©”ì¸ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë§ì´ ì—°êµ¬ë˜ê³  ìˆë‹¤. discrepancy-based methods, adversarial discriminative methods, generative modelì„ ë³€í˜•í•˜ê±°ë‚˜ ì ì ˆì´ ì„ì–´ê°€ë©° ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ì œì•ˆë˜ê³  ìˆë‹¤. ê·¸ ì™¸ì—ë„ ë¶„ë¥˜ê¸° ë¶ˆì¼ì¹˜ ë¶„ì„, ì—”íŠ¸ë¡œí”¼ ìµœì†Œí™”, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµê³¼ ê°™ì€ ë°©ë²•ë„ ì œì•ˆëœë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” taget ë„ë©”ì¸ê³¼ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ê³ , feature-level ê³¼ output-levelì— adversarial learningì„ ë„ì…í•¨ìœ¼ë¡œì¨ domain gapì„ ì¤„ì´ê³ ì í•œë‹¤.

> - adversarial learning : targetì˜ distributionì´ sourceì™€ ìœ ì‚¬í•˜ë„ë¡ í•™ìŠµì„ ì§„í–‰. source ìª½ì—ì„œ í•™ìŠµí•œ featureë“¤ì„ target domain conditionìœ¼ë¡œ ì˜®ê²¨ì£¼ê² ë‹¤ ë¼ëŠ” ì˜ë¯¸.
> - Generative network : target imageë¥¼ sourceì™€ ìœ ì‚¬í•˜ê²Œ ë§Œë“¤ì–´ì„œ í•™ìŠµì„ ì‹œí‚¤ì. í˜¹ì€ sourceì˜ styleì„ targetì— ë§ê²Œ ì¬ìƒì‚°í•´ì„œ í•™ìŠµì‹œí‚¤ì

> - Entropy minimization, Generative ëª¨ë¸, adversarial learningì„ í†µí•´ ë„ë©”ì¸ invariance representationì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì´ ì¢‹ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ë‹¤. 
> - ì—”íŠ¸ë¡œí”¼ ìµœì†Œí™”[31, 43], ìƒì„± ëª¨ë¸ë§[16, 12] ë° ì ëŒ€ì  í•™ìŠµ[42, 41]ì„ í†µí•´ ë„ë©”ì¸ ë¶ˆë³€ í‘œí˜„ì„ ì¶”ì¶œí•˜ëŠ” UDA ë°©ë²•ì— ì˜í•´ ì¸ìƒì ì¸ ê²°ê³¼ê°€ ë‹¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. 
> - ë©”ì¸ ê°„ ë¶ˆì¼ì¹˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ìˆ˜ë§ì€ UDA ë°©ë²•[19, 42, 43, 34]ì€ ì ëŒ€ì  í•™ìŠµì„ ë„ì…í•˜ì—¬ ë¶„í¬ ì¼ê´€ì„±ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ì´ë¯¸ì§€ì—ì„œ ì´ë¯¸ì§€ë¡œì˜ ë³€í™˜[21, 54]ì—ì„œ ì˜ê°ì„ ë°›ì•„ ì†ŒìŠ¤ ë°ì´í„°ì— ë”°ë¼ ëŒ€ìƒ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ UDA ë°©ë²• ë²”ì£¼ê°€ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤[19, 18]. 
> - ëŒ€ìƒ ì˜ì‚¬ ë ˆì´ë¸”ì„ ì‚¬ìš©í•œ ìì²´ ê°ë…ì€ ë¹„êµì  ê°„ë‹¨í•˜ì§€ë§Œ íš¨ìœ¨ì ì¸ ì ‘ê·¼ ë°©ì‹ì´ì§€ë§Œ[6, 55] ê°ë…ì„ ìœ„í•œ ì†ŒìŠ¤ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.
> - ì£¼ë¥˜ ì ‘ê·¼ ë°©ì‹ ì¤‘ í•˜ë‚˜ëŠ” ì ëŒ€ì  í•™ìŠµ[42, 41, 6, 5, 17, 37, 19]ì´ë©°, íŒë³„ìë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ë„ë©”ì¸ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. 
> - ìƒì„± ë„¤íŠ¸ì›Œí¬[38, 16, 50]ë¥¼ í™œìš©í•˜ì—¬ ì£¼ì„ì´ ë‹¬ë¦° ì†ŒìŠ¤ ì´ë¯¸ì§€ì— ìŠ¤íƒ€ì¼ ì „ì†¡ ê¸°ìˆ ì„ ì ìš©í•˜ì—¬ ëŒ€ìƒ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 
> - ì ëŒ€ì  í•™ìŠµ, ìƒì„± ê¸°ë°˜, ë¶„ë¥˜ê¸° ë¶ˆì¼ì¹˜ ë¶„ì„, ìê°€ í•™ìŠµ, ì—”íŠ¸ë¡œí”¼ ìµœì†Œí™”, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµê³¼ ê°™ì€ (ìƒí˜¸ ë°°íƒ€ì ì´ì§€ ì•Šì€) ë²”ì£¼ë¥¼ ê¸°ë°˜

## 2.3. Self-training

Self-trainingì€ ì†ŒëŸ‰ì˜ labeled ë°ì´í„°ê³¼ ë‹¤ëŸ‰ì˜ unlabeled ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•˜ëŠ” ë°©ì‹ì¸ Semi-supervised learning(SSL)ì˜ í•œ ë°©ë²•ì´ë‹¤. Labeled ë°ì´í„°ë¡œ ì¶©ë¶„íˆ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ unlabeled ë°ì´í„°ì— pseudo-labeling ì„ í•˜ê³ , pseudo labeled ë°ì´í„°ì™€ labeled ë°ì´í„°ë¥¼ í•¨ê»˜ í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤. 

Noisy Student(CVPR 2020), Meta Pseudo Labels(CVPR 2021)ëŠ” Teacher-student ê¸°ë°˜ì˜ Self-trainingìœ¼ë¡œ, labeled ë°ì´í„°ë¡œ í•™ìŠµëœ teacherë¥¼ ì´ìš©í•´ unlabeled ë°ì´í„°ì— pseudo-labeling í•˜ê³  ì´ ë°ì´í„°ì— ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ì—¬ student ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì´ë‹¤. Student ëª¨ë¸ì´ ì–´ëŠì •ë„ í•™ìŠµì´ ë˜ë©´ teacher ëª¨ë¸ë¡œ ì„¤ì •í•˜ê³  ë‹¤ì‹œ pseudo labelingì„ ìˆ˜í–‰í•˜ê²Œ ë§Œë“¤ì–´ ë°˜ë³µì ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í–ˆê³  ì´ë¥¼ í†µí•´ SOTAë¥¼ ê¸°ë¡í•  ì •ë„ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ ì—°êµ¬ì´ë‹¤.

> Noiseë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ regularization íš¨ê³¼ë¥¼ ì£¼ê³  ìƒˆë¡œìš´ inputë“¤ì— ëŒ€í•´ robust í•˜ê²Œ í•™ìŠµí•˜ë„ë¡ í•œë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í•™ìŠµëœ adaptation ëª¨ë¸ì„ ì‚¬ìš©í•´ unlabeled target ë°ì´í„°ì— pseudo-labelì„ ìƒì„±í•˜ê³ , í•™ìŠµ ë°ì´í„°ë¡œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ Self-training íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•¨ìœ¼ë¡œì¨ target ë„ë©”ì¸ì— ë§ê²Œ ëª¨ë¸ì„ fine-tuning í•œë‹¤.

> - ëŒ€ìƒ ë„ë©”ì¸ì˜ ì‘ì€ ì´ë¯¸ì§€ ì„¸íŠ¸ì—ë§Œ ì£¼ì„ì„ ë‹¬ê³  ë°˜ ì§€ë„ í•™ìŠµ(SSL) ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ë ˆì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì€ ë°ì´í„°ë¥¼ ì¶©ë¶„íˆ í™œìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤[10, 30, 9, 29]. SSL ì„¤ì •ì—ì„œ ë ˆì´ë¸”ë§ëœ ë°ì´í„°ì˜ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ íšë“í•œ ëª¨ë¸ì€ ë ˆì´ë¸”ë§ëœ ë°ì´í„°ì˜ ì†ŒëŸ‰ì— ê³¼ì í•©ë  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë„ë©”ì¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë ˆì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì€ ì œí•œëœ ë ˆì´ë¸”ì´ ì§€ì •ëœ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•ì€ í”½ì…€ ë‹¨ìœ„ ì˜ˆì¸¡ ì‘ì—…ì— ëŒ€í•œ ëª¨ë¸ì˜ ì •í™•ë„ì™€ ì¼ë°˜í™”ë¥¼ ê°œì„ í•˜ëŠ” ë° í•µì‹¬ì…ë‹ˆë‹¤
> - ìì²´ í›ˆë ¨[21, 51, 23, 14]ì— ê¸°ë°˜í•œ ì¼ë¶€ ë°©ë²•ì€ ë ˆì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì€ ë°ì´í„°ì˜ ì˜ì‚¬ ë ˆì´ë¸”ì„ ìƒì„±í•˜ê³  ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.
> - Self-Training : unlabeled dataë¥¼ ìœ„í•´ pseudo-labelsë¥¼ ìƒì„±í•´ì„œ í•™ìŠµí•˜ëŠ” ë°©ë²•. ìŠ¤ìŠ¤ë¡œ í•„ìš”í•œ GTë¥¼ ë‚˜ë¦„ëŒ€ë¡œ ë§Œë“¤ì–´ì„œ ê·¸ê±¸ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œë‹¤ëŠ” ì˜ë¯¸
> - ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í•™ìŠµëœ adaptation ëª¨ë¸ì„ ì‚¬ìš©í•´ unlabeled ë°ì´í„°ì— pseudo-labelì„ ìƒì„±í•˜ê³ , í•™ìŠµ ë°ì´í„°ë¡œ ì¬ì‚¬ìš© í•  ìˆ˜ ìˆë„ë¡ Self-training íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•œë‹¤.

# 3. ì œì•ˆ ë°©ë²•

Synthetic ë°ì´í„°ë§Œì„ í•™ìŠµëœ ëª¨ë¸ì€ real dataì™€ì˜ domain gapì´ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì—, ì‹¤ì œ real world ì—ì„œ ì‚¬ìš©í•˜ê¸°ì—ëŠ” ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— synthetic ë°ì´í„°ë§Œìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ì§ì ‘ adaptation í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ì§€ ì•Šê³ , unlabeled real dataì— pseudo-labeling í•´ì£¼ëŠ” teacher ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ê³ ì í•œë‹¤.

Adapted dataë¡œ task modelì„ ì¶©ë¶„íˆ í•™ìŠµì‹œí‚¤ê³ , í•™ìŠµëœ ëª¨ë¸ì„ unlabeled ë°ì´í„°ì— pseudo labelingì„ í•´ì¤€ë‹¤. ì–´ëŠì •ë„ labeled real dataê°€ ëª¨ì´ë©´ adapted dataì™€ real dataë¥¼ í•¨ê»˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ task modelì„ í•™ìŠµì‹œí‚¤ê³ , ì ì°¨ real datì˜ ë¹„ìœ¨ì„ ëŠ˜ë ¤ ë‚˜ê°ìœ¼ë¡œì¨ real worldì—ì„œë„ ì˜ ë™ì‘í•˜ëŠ” SSL í•™ìŠµ ë£¨í”„ë¥¼ êµ¬ì„±í•œë‹¤.

![](/assets/images/21-09-24-paper-overview.png)

1. Real dataì™€ synthetic dataë¥¼ ì‚¬ìš©í•´ GAN based DA ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤.
2. DA ëª¨ë¸ì˜ Generatorë¥¼ ì´ìš©í•´ synthetic dataë¡œë¶€í„° adapted synthetic dataë¥¼ ìƒì„±í•œë‹¤.
3. Adapted synthetic dataì™€ GT ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ task modelì„ ì¶©ë¶„íˆ í•™ìŠµì‹œí‚¨ë‹¤.
4. í•™ìŠµëœ task modelì„ teacher ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì—¬, unlabeled real dataì— pseudo-labeling í•œë‹¤.
5. Adapted synthetic dataì™€ pseudo labelingëœ real dataë¥¼ ì´ìš©í•´ task modelì„ ì¬í•™ìŠµì‹œí‚¨ë‹¤.
6. 4, 5 ê³¼ì •ì„ ë°˜ë³µí•œë‹¤.

ìœ„ì™€ ê°™ì€ í•™ìŠµ ë£¨í”„ë¡œ ë°˜ë³µì ìœ¼ë¡œ í•™ìŠµì„ ìˆ˜í–‰í•˜ë©° synthetic dataì™€ real data ê°„ì˜ domain gapì„ ì¤„ì´ê³ , ë™ì‹œì— pseudo-labeling ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í•¨ê»˜ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ êµ¬ì„±í•œë‹¤. ê·¸ë¦¬ê³  ë°ì´í„°ì— ë‹¤ì–‘í•œ Noise ê¸°ë²• ì‹¤í—˜, unbalanced data ë³´ê°• ë“±ì˜ ê¸°ë²•ë“¤ì„ ì´ìš©í•´ synthetic dataì˜ ì´ì ì„ ì‚´ë¦¬ê³  accuracyë¥¼ ëŒì–´ì˜¬ë¦´ ìˆ˜ ìˆë„ë¡ í•œë‹¤.
Real datasetê³¼ Synthetic datasetë¥¼ ì´ìš©í•´ semantic segmentationì„ ìˆ˜í–‰í•˜ê³  Class ë³„ IoU, mean IoU, pixel accuracyë¥¼ ë¹„êµí•˜ì—¬ ì œì•ˆí•œ ë°©ë²•ìœ¼ë¡œ ì„±ëŠ¥ì´ ì¢‹ì•„ì§ì„ í™•ì¸í•œë‹¤.


## Image Translataion

ë¨¼ì € Input-levelì—ì„œì˜ domain gapì„ ì¤„ì´ê¸° ìœ„í•´ source ë„ë©”ì¸ì˜ image appearanceê°€ target ë„ë©”ì¸ê³¼ ìœ ì‚¬í•˜ë„ë¡ ìƒì„±í•´ë‚¸ë‹¤. ëŒ€í‘œì ì¸ image-to-image translation ë°©ë²•ì¸ CycleGANì„ ì´ìš©í•˜ì—¬ target ë„ë©”ì¸ ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¡œ ë³€í˜•ì‹œì¼œ domain adaptation ëª¨ë¸ì˜ source ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ê³ ì í•œë‹¤.

$$ L(G, F, D_x, D_Y) = L_{GAN}(G, D_Y, X, Y) + L_{GAN}(F, D_x, Y, X) + \lambda L_{cyc}(G, F) $$
$$ G^*, F^* = arg min_{G, F} max_{D_x, D_y} L(G, F, D_x, D_y) $$

Adversiarl lossì™€ cycle consistency lossë¥¼ ê²°í•©í•œ ë°©ë²•ìœ¼ë¡œ, $X$ê°€ source ë„ë©”ì¸ ìƒ˜í”Œ, $Y$ê°€ target ë„ë©”ì¸ ìƒ˜í”Œì´ë¼ê³  í–ˆì„ ë•Œ, $X \rightarrow Y$ë¡œ ê°€ëŠ” GANì˜ adversarial lossì™€ $Y \rightarrow X$ë¡œ ê°€ëŠ” GANì˜ adversarial lossì— ê°ê° ì›ë³¸ìœ¼ë¡œ ë³µêµ¬í•˜ëŠ” cycle consistency lossë¥¼ ë”í•´ì¤€ ê°’ì´ total lossê°€ ë˜ê³ , ì´ lossë¥¼ ìµœì†Œí™” í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ $G: X \rightarrow Y$ì™€ $F: Y \rightarrow X$ë¥¼ í•™ìŠµì‹œí‚¨ë‹¤.

![](/assets/images/21-09-24-paper-style-transfer.png)
> GTA5(Source) ì´ë¯¸ì§€ë¥¼ Cityscapes(Target) ìŠ¤íƒ€ì¼ë¡œ image translation í•œ ê²°ê³¼

Source ë„ë©”ì¸ê³¼ target ë„ë©”ì¸ì˜ ë¶„í¬ë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì´ê¸° ë•Œë¬¸ì— ë„ë©”ì¸ ê°„ gapì´ ì¤„ì—ˆì„ ê²ƒì´ë¼ê³  ê°€ì •í•  ìˆ˜ ìˆê³ , í•´ë‹¹ ëª¨ë¸ì„ í†µí•´ ìƒì„±ëœ ë°ì´í„°ëŠ” target ë„ë©”ì¸ ë¶„í¬ì— ì¢€ ë” ê°€ê¹Œìš´ í˜•íƒœê°€ ë  ìˆ˜ ìˆë‹¤. Source ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒ ë³´ë‹¤ Target ë„ë©”ì¸ì— ë§ê²Œ ì´ë¯¸ì§€ë¥¼ ë³€í˜•í•˜ì—¬ target task ëª¨ë¸ì— ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆì—ˆëŠ”ë°, ì´ì— ê´€í•œ ì‹¤í—˜ ê²°ê³¼ëŠ” 4.3ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

# 4. ì‹¤í—˜ ë° ê²°ê³¼

> UDA ê¸°ìˆ ì˜ ì£¼ìš” ì¸¡ë©´ì€ í•œ ë°ì´í„°ì„¸íŠ¸ì—ì„œ íšë“í•œ ì§€ì‹ì„ ë‹¤ë¥¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ì´ì „í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ê³ ë ¤ëœ ë°ì´í„°ëŠ” UDA ì•Œê³ ë¦¬ì¦˜ì˜ ì„¤ê³„ ë° í‰ê°€ì—ì„œ ê·¼ë³¸ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” ê°€ì¥ í¥ë¯¸ë¡œìš´ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ í•˜ë‚˜ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤. 
> ê°ë…ë˜ì§€ ì•Šì€ ë„ë©”ì¸ ì ì‘ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ëŒ€ìƒ ë„ë©”ì¸ì— ìˆëŠ” ì‹¤ì œ ìƒ˜í”Œì˜ ê°’ë¹„ì‹¼ ë ˆì´ë¸”ì´ êµìœ¡ì— í•„ìš”í•˜ì§€ ì•Šë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì œí•œëœ ìˆ˜ì˜ ì‹¤ì œ ëŒ€ìƒ ìƒ˜í”Œì€ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸(ë•Œë¡œëŠ” ê²€ì¦)í•˜ê¸° ìœ„í•´ ìˆ˜ë™ìœ¼ë¡œ ë ˆì´ë¸”ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë©´ì— ì†ŒìŠ¤ ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” ëŒ€ê·œëª¨ í•©ì„± ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ì§€ë„ í•™ìŠµì— í™œìš©ë˜ëŠ” ì£¼ì„ì´ ì¥ì°©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## 4.1. ë°ì´í„°ì…‹

![](/assets/images/21-09-24-paper-dataset.png)

CityscapesëŠ” ìœ ëŸ½ 50ê°œ ë„ì‹œì˜ ê±°ë¦¬ì—ì„œ ì°¨ëŸ‰ ì‹œì ìœ¼ë¡œ ìº¡ì³í•œ 2048x1024 í”½ì…€ì˜ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì´ë‹¤. 2,975ê°œì˜ training set, 500ê°œì˜ validation set, 1,595ê°œì˜ test setìœ¼ë¡œ ì´ 5,000ê°œì˜ ì´ë¯¸ì§€ ë°ì´í„°ì™€ pixel-wise semantic labelë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì¶”ê°€ë¡œ label ë˜ì–´ ìˆì§€ ì•Šì€ 19,998 ê°œì˜ raw ì´ë¯¸ì§€ ë°ì´í„°ë„ ì œê³µëœë‹¤.

GTA5ëŠ” ë„ì‹œ ìš´ì „ì„ ìœ„í•œ ëŒ€ê·œëª¨ synthetic ë°ì´í„°ì…‹ ì¤‘ í•˜ë‚˜ì´ë‹¤. ì‚¬ì‹¤ì ì¸ ê·¸ë˜í”½ì„ ë³´ì—¬ì£¼ëŠ” GTA V ê²Œì„ì„ í†µí•´ ë Œë”ë§ ë˜ì—ˆê³  ë¯¸êµ­ ìŠ¤íƒ€ì¼ ë„ì‹œì—ì„œì˜ ìë™ì°¨ ê´€ì ì—ì„œ ì´¬ì˜ë˜ì—ˆë‹¤. 24,966ê°œì˜ 1914x1052 í”½ì…€ì˜ ì´ë¯¸ì§€ì™€ pixel-wise semantic labelë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. Labelì€ Cityspcaesì˜ í´ë˜ìŠ¤ì— ë§ê²Œ 19ê°œ í´ë˜ìŠ¤ë¡œ ì¬ë§¤í•‘ í•  ìˆ˜ ìˆë‹¤.

|  Dataset   |   Type    | # of Labeled Data | # of Raw Data | # of Classes |
| :--------: | :-------: | :---------------: | :-----------: | :----------: |
| Cityscapes |   Real    |       5,000       |    19,998     |      19      |
|    GTA     | Synthetic |      24,966       |       -       |      19      |

Cityscapesì™€ GTA5ëŠ” ì‹œê°ì ì¸ appearance ì°¨ì´ê°€ ì¡´ì¬í•˜ì§€ë§Œ ë¹„ìŠ·í•œ ì°¨ëŸ‰ì˜ ë†’ì´ì—ì„œ ë„ë¡œ ìƒí™©ì„ ìº¡ì³í•œ ë°ì´í„°ë¼ëŠ” ì ì—ì„œ êµ¬ì¡°ê°€ ìœ ì‚¬í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. GTA5 ë°ì´í„°ê°€ Cityscapes ë°ì´í„° ì–‘ì— ë¹„í•´ ì•½ 5ë°° ê°€ëŸ‰ ë§ê¸° ë•Œë¬¸ì— GTA5ì˜ ë°ì´í„°ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ ì˜ë¯¸ì™€ êµ¬ì¡°ë¥¼ í•™ìŠµí•˜ê³ , Cityscapesì˜ unlabeled ë°ì´í„°ê¹Œì§€ ì ì ˆíˆ ì´ìš©í•˜ì—¬ Cityscapes í™˜ê²½ì—ì„œ ì˜ ë™ì‘í•˜ëŠ” Semantic segmentation ëª¨ë¸ì„ ë§Œë“¤ê³ ì í•œë‹¤.

## 4.2. í‰ê°€ Metric

í‰ê°€ metricìœ¼ë¡œëŠ” Semantic segmentation í‰ê°€ ì‹œì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” í´ë˜ìŠ¤ ë³„ IoU(Intersection over Union) ì™€ mIoU(Mean Intersection over Union)ë¥¼ ì‚¬ìš©í•œë‹¤. $TP_i$, $FP_I$, $FN_i$ ëŠ” íŠ¹ì • í´ë˜ìŠ¤ $i$ì˜ True Positive, False Positive, False Negative ì´ê³  $N$ì€ í´ë˜ìŠ¤ì˜ ê°¯ìˆ˜ì´ë‹¤.

$$ {IoU}_i = \left( \frac{TP_i}{FP_i + FN_i + TP_i} \right) $$

$$ mIoU = \sum_{i=1}^N \left( \frac{IoU_i}{N} \right ) $$

## 4.3. Image Translation ì‹¤í—˜

### Directly transfer (segmentation model ê·¸ëŒ€ë¡œ ì‚¬ìš©)
- Directly transfer í–ˆì„ ë•Œ domain shiftì— ì˜í•œ ì„±ëŠ¥ì €í•˜ë¥¼ í…ŒìŠ¤íŠ¸
- target ë„ë©”ì¸ ìƒ˜í”Œë§Œì„ ì‚¬ìš©í•˜ì—¬ Resnet-50ì„ backboneìœ¼ë¡œ í•œ DeepLab v3+ ëª¨ë¸ í•™ìŠµ
- Real datasetìœ¼ë¡œ í•™ìŠµëœ Semantic Segmentation(Task ëª¨ë¸)ì„ synthetic ë°ì´í„°ì— ì ìš©í–ˆì„ ë•Œ, synthetic dataì—ì„œ real dataë¡œ adaptation ëœ ë°ì´í„°ì— ì ìš©í–ˆì„ ë•Œ ê°ê° ì–´ëŠ ì •ë„ì˜ ì„±ëŠ¥ ì°¨ì´ê°€ ë°œìƒí•˜ëŠ”ì§€ ë¹„êµí•œë‹¤.

![](/assets/images/21-09-24-paper-image-translation-experiments.png)

|                       | Pixel Accurach |  mIoU  |
| :-------------------: | :------------: | :----: |
|     Source Domain     |     72.100     | 30.180 |
| Source->Target Domain |     79.077     | 36.265 |
|     Target Domain     |     95.826     | 74.979 |

---

![](/assets/images/21-09-24-paper-style-transfer-prediction.png)

- CycleGANì„ ì´ìš©í•´ GTA -> Cityscapes ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ DA
- generative modelì„ ì´ìš©í•´ appearanceë¥¼ ë¹„ìŠ·í•˜ê²Œ style transfer í–ˆì„ ë•Œ domainì˜ gapì´ ì ì–´ì§„ë‹¤

### Domain Adaptation 

```sh
# Source: GTA
# Target: Cityscapes
# domain adaptation ëª¨ë¸ì„ í†µí•´ task ëª¨ë¸ì˜ mIoU ì¸¡ì •
===>road:       83.99
===>sidewalk:   10.25
===>building:   74.36
===>wall:       4.47
===>fence:      3.08
===>pole:       10.36
===>light:      11.83
===>sign:       11.46
===>vegetation: 84.24
===>terrain:    15.83
===>sky:        68.71
===>person:     39.09
===>rider:      0.15
===>car:        79.1
===>truck:      26.16
===>bus:        17.3
===>train:      0.0
===>motocycle:  2.78
===>bicycle:    0.01
===> mIoU: 28.59
```

```sh
# Source: Cityscapes ìŠ¤íƒ€ì¼ì˜ GTA5 ë°ì´í„°
# Target: Cityscapes
# domain adaptation ëª¨ë¸ì„ í†µí•´ task ëª¨ë¸ì˜ mIoU ì¸¡ì •
===>road:       89.43
===>sidewalk:   26.21
===>building:   82.72
===>wall:       25.88
===>fence:      22.92
===>pole:       36.15
===>light:      40.42
===>sign:       38.88
===>vegetation: 84.1
===>terrain:    37.55
===>sky:        83.52
===>person:     59.09
===>rider:      26.71
===>car:        83.65
===>truck:      28.55
===>bus:        36.64
===>train:      0.14
===>motocycle:  14.6
===>bicycle:    26.76
===> mIoU: 44.42
```



## 4.3. Data dependency ì‹¤í—˜

- ì ì€ target ë°ì´í„°ì…‹ìœ¼ë¡œ ì˜ í›ˆë ¨ë  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ labeled ë°ì´í„°ë¥¼ ì¤„ì—¬ê°€ë©° ì‹¤í—˜
- ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ì˜ í›ˆë ¨ë  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€
- SSL ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ë³´í†µ Labled ë°ì´í„°ë¥¼ ì ê²Œ ì‚¬ìš©í•˜ê³  Unlabeld ë°ì´í„°ë¥¼ ë§ì´ ì‚¬ìš©í•´ í…ŒìŠ¤íŠ¸í•œë‹¤.

## 4.5. Performance ì‹¤í—˜

- ì•Œê³ ë¦¬ì¦˜ì´ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰ë˜ëŠ”ì§€
- SOTA ëª¨ë¸ê³¼ ë¹„êµ

# 5. ê²°ë¡ 

# 6. ì°¸ê³  ë¬¸í—Œ

- [Cycle-GAN](Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks)

---

1. Abstract
2. Introduction
3. Related Work
4. Method
5. Experiments
6. Conclusions
7. References

---

# ë§í¬

- [ë…¼ë¬¸ì‹¬ì‚¬ì¼ì •](https://eyonsei.yonsei.ac.kr/info.asp?mid=m03_10)
- [í•™ìœ„ë…¼ë¬¸ ì‘ì„±ë²•](https://graduate.yonsei.ac.kr/graduate/academic/notice_haksa.do?mode=view&articleNo=28347&article.offset=0&articleLimit=10&srCategoryId1=363)

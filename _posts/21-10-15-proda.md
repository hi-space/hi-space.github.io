---
title: Prototypical Pseudo Label Denoising and Target Structure Learning for Domain Adaptive Semantic Segmentation
category: AI
tags: ai paper 🔥
cover: /assets/images/21-10-15-proda-2021-10-15-10-50-03.png
---

- CVPR 2021
- [Paper](https://arxiv.org/pdf/2101.10979.pdf)
- [Github](https://github.com/microsoft/ProDA)

<!--more-->

# Abstract

Self-training은 도메인 적응적 Segmentation에서 경쟁적인 접근 방식으로, 대상 도메인의 의사 라벨로 네트워크를 훈련시킨다. 그러나 필연적으로, 의사 라벨은 노이즈가 발생하며, 원본과 대상 도메인 사이의 불일치로 인해 대상 특징 (Target Feature)가 분산된다.

본 논문에서는 비감독 도메인 적응을 위한 두 가지 문제를 해결하기 위해, 클래스의 특징 중심인 대표적인 프로토타입에 의존한다. 특히, 우리는 한 걸음 더 나아가 단순한 프로토타입보다 더 풍부한 정보를 제공하는 프로토타입으로부터의 특징 거리(Feature Distances)를 이용한다.

구체적으로, 훈련 과정에서 온라인 수정을 용이하게 하기 위해 의사 라벨의 가능성을 추정하기 위해 사용한다.

한편, 우리는 동일한 대상의 두 가지 다른 뷰에 대한 상대적 특징 거리를 기반으로 원형 할당을 정렬하여보다 컴팩트한 대상 특징 공간을 생성한다.

게다가, 우리는 이미 배운 지식을 스스로 감독하는 사전 훈련된 모델로 증류하는 것이 성능을 더욱 향상시킨다는 것을 발견한다. 우리의 방법은 최첨단 방법보다 엄청난 성능 우위를 보여준다.

# Introduction

컴퓨터 비전에서 깊은 학습의 놀라운 성공에도 불구하고 높은 성능을 얻으려면 방대한 양의 데이터가 필요합니다. 일반적으로 시맨틱 세그멘테이션과 같은 밀도 높은 예측 작업에 대한 레이블을 얻는 데 비용이 많이 든다. 따라서 사람들은 자유롭게 생성된 라벨을 사용하여 풍부한 광현실적 합성 이미지를 활용하는 것을 생각한다.

그러나 **깊은신경망(Deep neural networks)은 렌더링된 이미지의 미묘한 비현실주의가 실제 데이터에 대한 잘못된 일반화를 유도한다는 도메인 오정렬에 민감하다는 악명이 높다**. **이러한 문제를 해결하기 위해 도메인 적응 기법은 합성 이미지(소스 도메인)에서 학습한 지식을 최소한의 성능 손실로 실제 이미지(목표 도메인)로 전달하는 것을 목표로 한다**. 본 논문에서는 대상 도메인에 접근 가능한 레이블이 없는 도전적인 경우인 UDA(Unsupervised domain adaptation)에 초점을 맞춘다. 구체적으로**, 우리는 의미 분할(Semantic Segmentation)을 위한 UDA 문제를 해결**한다.

소스 및 대상 도메인의 분포를 가장 우세한 솔루션[6, 28, 49, 55, 59], 자기 훈련[35, 69, 75, 76]으로 명시적으로 정렬하기 보다는 최근 UDA 작업에서 간단하지만 경쟁적인 접근으로 부상했다. 이는 대상 데이터에 대한 가장 자신있는 예측에 기초하여 의사 레이블 세트를 반복적으로 생성한 다음 네트워크를 재교육하기 위해 이러한 의사 레이블에 의존함으로써 달성된다. 이러한 방식으로 네트워크는 점차 자기주도적 교육과정 학습에서 적응을 학습한다.

그러나 성능은 여전히 몇 가지 라벨이 붙은 샘플을 사용하여 감독된 학습이나 Semi-감독학습에 크게 뒤쳐져, 실제 시나리오에서 감독되지 않은 도메인 적응을 비실용적으로 만든다.

자기 훈련(Self-training)을 해부해보니, 우리는 이전 작업에서 두 가지 핵심이 부족하다는 것을 발견한다. 

첫째, 일반적인 연습 [75, 76]은 엄격한 신뢰 임계값에 따라 의사 레이블을 선택하는 것을 제안하지만, 높은 점수가 반드시 정확하지는 않아 네트워크가 대상 도메인에서 신뢰할 수 있는 지식을 배우지 못하게 한다.
둘째, 도메인 간 차이로 인해 네트워크는 대상 도메인에 분산된 피쳐를 생성하기 쉽다. 대상 데이터의 경우 소스 분포에 가까울수록 신뢰 점수가 높을 가능성이 높다.

그 결과, 소스 분포에서 멀리 떨어진 데이터(즉, 낮은 점수)는 훈련 중에 고려되지 않는다.

본 문서에서는 **위의 두 가지 문제를 각각 해결하기 위해 의사 레이블의 노이즈를 제거하고 컴팩트한 대상 구조를 학습할 것을 제안**한다. 두 작업을 수행하기 위해 프로토타입(예: 클래스별 피쳐 중심)에 의존한다.

(1) **모든 클래스 프로토타입에 대한 상대적 특징 거리에 따라 클래스별 우도(likelihoods)를 추정하여 의사 레이블을 수정**한다. 이것은 프로토 타입이 기본 클러스터의 실제 중심에 더 가깝다는 실제 가정에 달려 있으며, 거짓 의사 레이블이 소수 안에 있음을 암시한다. 프로토 타입은 즉시 계산되므로 의사 레이블은 훈련 내내 점진적으로 수정된다는 점에 주목할 필요가 있다.
(2) 우리는 딥클러스터(Deepcluster)로부터 영감을 얻어 목표 영역의 본질적인 구조를 배운다. **클러스터 할당에서 직접 학습하는 대신, 동일한 대상의 다른 뷰에 대해 소프트 프로토타입 할당을 정렬하여 보다 컴팩트한 대상 피쳐 공간을 생성할 것을 제안**한다. 우리는 도메인 적응을 위한 프로토타입에 크게 의존하기 때문에 **ProDA** 방법을 참조한다 .

위의 기술로 보완한 우리의 ProDA는 이전 작업보다 분명한 우월성을 보여줄 수 있다. 또한 도메인 적응은 Task에 구애받지 않는 사전 훈련의 혜택을 받을 수 있다는 것을 발견한다. 즉, 지식을 자기 감독(Self-supervised) 모델로 증류하는 것은 성능을 더욱 높여 기록적인 높은 수준으로 끌어올린다. 

본 연구의 공헌은 다음과 같이 요약할 수 있다.

- 우리는 프로토타입과의 상대적 특징 거리에 따라 소프트 의사 라벨 (Soft pseudo label)을 온라인으로 수정하는 것을 제안하지만 프로토타입은 즉시 업데이트된다.

따라서 네트워크는 훈련 내내 노이즈가 제거된 의사 라벨로부터 배운다.

- 우리는 소형 표적 특징 공간을 얻을 수 있도록 증강된 관점의 학습을 가르치기 위해 부드러운 원형 할당에 의존할 것을 제안한다.
- 이미 배운 지식을 자기 감독 사전 훈련 모델로 증류하면 성능이 크게 향상된다는 것을 보여준다.
- 제안된 ProDA는 최첨단보다 훨씬 뛰어나다.
Deeplabv2 네트워크로써 우리의 방법은 GTA5와 SYNTHIA 데이터셋에서 적응할 때 Cityscapes segmentation mIOU를 57.5와 55.5로 달성하여, 이전의 선행 접근법에 비해 적응 이득을 각각 52.6%와 58.5% 향상시켰다.

## Related Work

## 감독되지 않은 도메인 적응(Unsupervised domain adaptation.)

이론적 분석 [3]에서 제시한 바와 같이, 도메인 정렬 방법은 이미지 레벨 [1, 12, 13, 20, 27, 50, 64], 중간 특징 레벨 [6, 28, 49, 59] 또는 출력 레벨 [55]에서 일부 발산 [31, 36]을 최적화하거나 적대적 훈련 [21, 41]을 채택함으로써 분포 불일치를 줄이는 데 초점을 맞추고 있다.

그러나 글로벌 분포를 정렬하면 목표 도메인 [7, 29, 72]에서 작은 기대 오차를 보장할 수 없다. 최근의 접근법 [18, 37, 60]은 미세한 특징 정렬을 촉진하기 위해 클래스 방식으로 분포를 정렬하려고 시도한다. 사실 특징이 잘 분리된 이상 분포를 엄격하게 정렬할 필요가 없다.

반면 반감시학습(SSL)에서 유래한 기법은 경쟁적인 성능을 제공한다.

엔트로피 최소화 및 그 변형 [9, 47, 58]은 라벨이 없는 대상 데이터에 대해 Network가 예리하게  예측하도록 유도하며, 그 결과 Network는 잘못된 추정치를 지나치게 신뢰하기 쉽다. 이를 해결하기 위해 반복적으로 생성된 의사 레이블을 활용하는 자체 훈련 [75]이 제안되었다. 하지만 의사 라벨은 어쩔 수 없이 노이즈가 발생할 수 밖에 없다. 따라서 [76]은 신뢰 정규화 용어를 망에 추가하고 [73]은 신뢰할 수 없는 레이블의 부작용을 줄이기 위해 예측 신뢰 맵(prediction confidence map)을 명시적으로 추정한다. [35]에서 자기 훈련과 이미지 변환은 상호 유익한 것으로 판명된다. 최근의 작업 [69]은 범주형 중심에 기반한 의사 레이블을 생성하고 범주 수준에서 피쳐 정렬을 시행한다. 그러나 이러한 자기 훈련 접근법은 대체 방식으로 최적화된다. 즉, 레이블은 표현 학습 과정에 고정되어 있으며 전체 훈련 단계 이후에만 업데이트된다.

대조적으로, 우리는 목표 도메인에서 추정된 프로토타입 컨텍스트에 따라 거짓 추정치를 증류하는 온라인 의사 레이블 업데이트 방법을 제안한다.

## 감독받지 않은 표현 학습.

최근, 감독되지 않은 학습에 대한 연구 관심은 급증하고 있다 [43]. 초기 노력은 목표 데이터 [48, 54, 67]에서 보조 작업으로 활용 될 때 UDA에 유익한 것으로 입증된 구실 작업 [17, 19, 30, 70]을 설계하는 데 전념한다.

감독된 학습과의 격차는 대조적인 학습을 기반으로한 몇 가지 저명한 작품 [10, 24]에 의해 상당히 좁혀져 있다. 최근 일련의 작품 [2, 5, 22, 40]은 네트워크가 다른 증강된 뷰 하에서 일관성이 있는한 풍부한 의미론적 특징을 배울 수 있음을 발견한다.

그러나 이러한 방법은 이미지와 같은 차별을 가정하여 세그먼트화 작업에 대한 픽셀 수준의 의미론을 배우는 데 적합하지 않다. 이 연구는 UDA 문제와 일치하는 일관된 학습과 클러스터 기반 표현 학습의 조합을 발견하고 Deepcluster [4]에서 영감을 얻은 소형 목표 특징 공간을 학습한다.

다르게, 우리는 다른 증강 뷰에 대한 클러스터 할당보다는 상대 피쳐 거리를 정렬한다.

## Noisy한 레이블에서 배움.

신중한 임계값에도 불구하고, 자기 훈련은 여전히 노이즈가 많은 의사 라벨을 제공한다. 따라서 이 작품은 노이즈가 많은 레이블에서 배우는 새로운 기술 [53]에 의해 동기 부여된다. 간단한 방법은 강력한 손실을 설계하는 것이지만, 이런 방법은 노이즈가 많은 데이터를 처리하지 못한다. 자기 라벨 수정 [52, 62, 73, 74]은 더 매력적인 접근법이다. 이 범주의 일반적인 방법은 두 명 또는 여러 학습자를 동시에 훈련시키고 추정치의 일치를 사용하여 라벨 신뢰성을 측정하는 것이다. 제안된 의사 레이블 노이즈 제거는 일부 복잡한 휴리스틱에 의해 결정된 프로토 타입에 따라 잘못된 레이블을 온라인으로 수정하는 [23]에 더 가깝다. 대조적으로, 우리는 즉시 프로토타입을 계산할 수 있다. 반면 지식 증류(KD:knowledge distillation)[26·33·34·66]는 인맥이 스스로 학습하더라도 교사 모델에서 학생에게 깨끗한 지식을 전달하는 데 효과적이라는 것을 입증했다 [10·33]다. 자기감독 사전 훈련 모델에 대한 지식 증류가 우리 작업에서 수행 한계를 더욱 밀어붙인다는 것을 증명한다.

![](/assets/images/21-10-15-proda-2021-10-15-10-50-03.png)

그림 1: Feature Space를 시각화하여 기존 자기 훈련의 문제를 설명한다.
(a) 결정 경계 (점선)는 해당 데이터의 분포를 교차시켜 부정확한 의사 라벨 추정치를 유도한다. 의사 레이블을 만들 때 네트워크에서 대상 분포를 모르기 때문이다. 이를 해결하기 위해 각 클래스의 프로토타입을 즉석에서 계산하고, 이 프로토타입에 의존해 거짓 의사 라벨을 온라인으로 수정한다.
(b)망은 선형 분류기로 구별되지 않는 표적 도메인에 분산된 특징 분포를 유도할 수 있다.

# Methods

## 4.1 프로토타입 의사 라벨 소음 제거

우리는 네트워크에 이미 노이즈가 많이 낀 라벨을 너무 많이 가지고 있어서, 훈련 단계가 지나면 의사 라벨을 업데이트하는 것이 너무 늦을 것이라고 추측한다. 반면 의사표시와 인맥 가중치를 동시에 업데이트하면서 사소한 해결책을 내놓기 쉽다.

이 논문은 간단한 방법을 제시하고, 간단한 방법을 통해 의사 라벨을 업데이트하고, 간단한 해결책을 피한다.

핵심은 소프트 의사 라벨을 수정하고 클래스별 확률에 따라 점진적으로 가중치를 부여하는 것인데, 새로 배운 지식에 따라 업데이트가 이루어진다.

공식적으로는 자체 훈련에 무게가 실린 의사표시를 활용하자고 제안한다.

## 4.2 일관성을 적용해 Structure 학습 실시.

피쳐 추출기 f가 컴팩트한 대상 피쳐를 생성할 때 의사 레이블의 노이즈를 제거할 수 있다. 그러나 도메인 차이로 인해 생성된 타겟 분포는 그림 1 (b)에서와 같이 분산 될 가능성이 더 높다. 이 경우 프로토 타입은 소스 모델에서 표적 피쳐가 잘 분리되어 있을 때조차도 클러스터의 맨 끝에 피쳐가 있는 데이터의 레이블을 수정하지 못한다. 최근의 연구 [42]는 Semi감독 학습에서이 문제를 확인했지만 일부 의사 레이블 데이터가 대상 도메인의 전체 분포를 커버할 수 없기 때문에 도메인 적응에서 문제가 악화된다.

이를 위해 표적 도메인의 기본 구조를 배우고 의사 라벨 증류에 우호적인 더 컴팩트한 특징을 얻길 희망한다. 최근 무감독 학습의 성공에 동기를 부여받으면서 클러스터링과 표현학습을 동시에 수행한다.원시과제에 대한 학습과는 달리 약한 증강 아래서 프로토타입 할당을 사용하여 강력한 증강 뷰에 대한 학습을 안내한다.

## 4.3.자기감독모델의 증류

방정식 11을 활용한 훈련이 수렴된 후, 우리는 학습된 목표 모델에서 동일한 아키텍처를 가진 학생 모델로 지식을 전달하지만 자체 감독 방식으로 미리 훈련된다. 구체적으로는 Sim-CLRv2 [11] 사전 훈련된 가중치로 학생 모델의 특징 추출기를 초기화하고 라벨이 없는 대상 이미지에 대한 추정 KL 차이를 최소화하여 교사를 모방할 수 있는 지식 증류(KD) 손실을 적용한다. 또한 자기 훈련 패러다임에 따라 교사 모델 h에 의존하여 one-hot 의사 레이블(pt)을 만들어 학생 모델을 가르치고 있다.모델이 소스 도메인을 잊지 않도록 소스 이미지도 사용된다.

![](/assets/images/21-10-15-proda-2021-10-15-10-50-35.png)

그림 2: ProDA 온라인은 학습 과정 내내 의사 라벨을 세분화합니다. 첫 번째 열은 Segmentation 입력이다. 두 번째 열에서 네 번째 열은 1k, 10k 및 40k 반복 후의 유사 레이블을 보여 준다.

![](/assets/images/21-10-15-proda-2021-10-15-10-50-47.png)

그림 3: 학습 과정 내내 의사 라벨의 평균 정확도 및 평균 IoU 점수 교육 단계 후에만 의사 라벨을 업데이트하는 기존의 자체 훈련에 비해, 우리 방법의 의사 라벨은 학습이 진행될수록 꾸준히 개선된다.

![](/assets/images/21-10-15-proda-2021-10-15-10-50-59.png)

그림 4: 여러 라벨의 가중치 조정 교육 곡선
온라인 레이블 업데이트 시 구성표. 고정된 pt,0 레이블을 채택하면 비고정 의사 레이블 pt로 학습을 방해하는 사소한 솔루션을 피할 수 있다. 점선은 기존 자체 훈련의 성과를 나타낸다.

순수한 자기 훈련은 여러 훈련 단계에 걸쳐 있다.

### 퇴행성 솔루션을 어떻게 막을 것인가?

자기 훈련 중에 피쳐를 배우고 레이블을 업데이트하면 퇴행성 솔루션이 생성된다. 이러한 변질을 피하기 위한 핵심은 고정된 소프트 라벨 pt,0을 증류 (식 3)에 무게 wt를 적용하는 보일러 플레이트로 채택하는 것이다. 이를 설명하기 위해 우리는 자기 훈련 라벨이 동적인 Pt 또는 고정인 Pt일 수 있는 그림 4에서 업데이트된 온라인 라벨에 대한 다른 변형을 조사하고 변조 가중치는 프로토 타입에 따라 추정된 네트워크 예측 Pt 또는 추정된 신뢰 wt일 수 있다. 또한 하드 라벨을 사용하는 것이 장점 인 것을 조사한다.

그림 4는 고정되지 않은 소프트 추정치 (pt 및 그 변형)를 사용할 때 성능이 잠시 상승한 다음 크게 떨어지기 시작하지만 고정된 추정치 (pt;0 및 그 변형)를 사용하는 학습은 훈련 내내 꾸준히 향상되고 기존 자기 훈련보다 우수하다는 것을 보여준다.

우리는 pt,0을 고정하면 증류된 의사 레이블이 이 초기 추정치에서 거의 벗어나지 않아 사소한 해결책을 피할 수 있다고 추측한다. 또한, 재 가중을 위해 pt를 사용하는 것과는 달리, 프로토타입 재 가중화는 mIoU를 5.0 이상 향상시켜 라벨 조정을 위한 프로토 타입 사용의 중요성을 확증한다. 또 소프트 라벨보다 하드 라벨을 사용해 약간의 개선(0.2)을 관찰한다.

### 목표 구조 학습의 효과.

본지는 대상 영역에 대한 내재적 지식을 배양하고 그 기반 구조를 학습할 것을 제안한다. 표 11에서 볼 수 있듯이 라벨 노이즈를 제거하지 않고 구조 학습은 45.6에서 47.6으로 성능을 향상시킬 수 있다. 또한 자기 훈련 접근법 중에서 경쟁적이지만 자신만 만족하는 의사 레이블을 선택하기 위해 임계값을 신중하게 선택할 필요가 없다. 목표 구조 학습은 컴팩트한 피쳐 클러스터를 형성하여 의사 레이블 노이즈 제거를 지원하고 성능 향상을 1.4까지 가져 왔다.

### 자체 감독 모델로 증류하는 효과.

두번째 학습 단계에서는 지식 증류를 적용해 1단계 모델의 암흑 지식(Dark knowledge)을 현재 단계로 전달한다. 표 11은 또한 이 단계에 대한 다른 초기화 전략을 비교해. 마지막 단계 훈련을 재개하는 것에 비해 자기 감독 사전 훈련 모델 (즉, SimCLRv2)의 초기화는 mIoU를 0.6까지 향상시키는 반면, 감독된 사전 훈련과의 초기화는 성능을 저하시킨다. 자체 감독 사전 훈련이 더 강력한 전달 가능성을 가지고 있고 광범위한 다운스트림 작업에 도움이 될 수 있기 때문이다. 이렇게 초기화하면 모델이 마지막 단계에서 로컬 최적에서 탈출할 수 있다. 표 11은 또한 지식 증류의 효과를 증명한다.이 구성 요소를 제거하면 mIoU가 1.1로 떨어지게된다. 지식 증류를 통한 3단계가 도메인 적응 없이 모델에 비해 20.9mIoU 향상을 달성하면서 0.6의 성능을 한층 향상시킨 것은 놀라운 일이다.

### 대상 피쳐의 UMAP 시각화.

![](/assets/images/21-10-15-proda-2021-10-15-10-51-17.png)

그림 5: UMAP를 사용하여 피쳐를 2D 공간에 매핑하는 피쳐 공간의 시각화.
명확한 예시를 위해, 우리는 파란색은 건물, 회색은 교통 표지, 주황색은 기둥, 녹색은 식물의 네 가지 종류만 보여준다.

직관을 더 잘 개발하기 위해, 우리는 그림 5에서 ProDA에 대해 배운 특징들을 시각화해. 도메인 적응 전 모델은 동일한 클래스의 피쳐를 혼합한다. 기존의 자기 훈련은 더 분리된 특징 공간을 생성할 수 있지만 선형 분류에는 여전히 어렵다. 원형 사이비 라벨 조정을 적용할 때 분포가 여전히 분산되어 있지만 다른 클래스 간의 특징은 더 잘 분리되어 있다. 비교에서 전체 모델은 분류에 적합한 가장 컴팩트한 피쳐 클러스터를 제공한다.

![](/assets/images/21-10-15-proda-2021-10-15-10-51-29.png)

## 5.4. 매개변수 민감도 분석

![](/assets/images/21-10-15-proda-2021-10-15-10-51-52.png)

프로DA가 하이퍼 매개 변수 선택에 강하다는 것을 보여주기 위해 매개 변수의 영향을 분석해. 표 4에서는 의사 레이블을 선택하기 위해 다른 임계값을 사용하며 성능은 기존 자체 훈련과 달리이 임계값에 민감하지 않다. 따라서, ProDA는 편리한 사용을 위해 임계값을 적용하지 않는다.또한 프로토 타입을 온라인으로 계산할 때 운동량 값의 영향을 연구하고 ProDA는 표 5와 같은 넓은 수치 범위에 강건한다.

# Conclusion

본 논문에서는 프로토타입에 의지하여 온라인 의사 레이블의 노이즈를 제거하고 대상 도메인에 대한 컴팩트 피쳐 공간을 학습하는 ProDA를 제안한다. 자기 감독된 사전 훈련된 모델로 지식을 증류하면 성능이 더욱 향상된다. 제안된 방법은 최신 방법을 크게 능가하여 감독된 학습과의 격차를 크게 줄여준다.
우리는 제안된 방법이 일반적으로 자기 훈련에 대한 개선이라고 생각하며, 향후 다른 작업에서 그 능력을 탐구하기를 희망한다.